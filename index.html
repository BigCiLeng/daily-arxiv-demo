<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>arXiv Daily Digest</title>
  <style>
    :root {
      --bg-surface: #ffffff;
      --bg-app: #f4f6fb;
      --text-primary: #1f2933;
      --text-secondary: #4b5563;
      --brand: #2563eb;
      --brand-soft: rgba(37, 99, 235, 0.12);
      --border: #e2e8f0;
      --danger: #dc2626;
    }
    *, *::before, *::after {
      box-sizing: border-box;
    }
    body {
      font-family: "Inter", -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
      margin: 0;
      background: var(--bg-app);
      color: var(--text-primary);
      line-height: 1.6;
      scroll-behavior: smooth;
    }
    header {
      background: radial-gradient(circle at top left, rgba(37, 99, 235, 0.82), #0f172a);
      color: white;
      padding: 36px 0 48px;
      box-shadow: 0 30px 60px rgba(15, 23, 42, 0.35);
    }
    header .inner {
      max-width: 1320px;
      margin: 0 auto;
      padding: 0 32px;
      display: flex;
      flex-direction: column;
      gap: 16px;
    }
    .page-title {
      font-size: clamp(2.2rem, 3vw, 2.8rem);
      font-weight: 700;
      margin: 0;
    }
    .page-meta {
      display: flex;
      flex-wrap: wrap;
      gap: 18px;
      font-size: 0.95rem;
      color: rgba(248, 250, 252, 0.85);
    }
    .page-meta span::before {
      content: "•";
      margin: 0 8px 0 4px;
      opacity: 0.5;
    }
    .page-meta span:first-child::before {
      content: "";
      margin: 0;
    }
    .source-switcher {
      display: inline-flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-top: 6px;
    }
    .source-button {
      appearance: none;
      border: 1px solid rgba(148, 163, 184, 0.35);
      background: rgba(15, 23, 42, 0.2);
      color: white;
      padding: 6px 16px;
      border-radius: 999px;
      font-weight: 600;
      cursor: pointer;
      transition: background 0.2s ease, transform 0.2s ease, border-color 0.2s ease;
    }
    .source-button:hover,
    .source-button:focus {
      background: rgba(37, 99, 235, 0.35);
      border-color: rgba(96, 165, 250, 0.75);
      outline: none;
    }
    .source-button.is-active {
      background: white;
      color: var(--brand);
      border-color: transparent;
      box-shadow: 0 6px 18px rgba(14, 116, 244, 0.35);
      transform: translateY(-1px);
    }
    .display-mode {
      display: inline-flex;
      flex-wrap: wrap;
      gap: 8px;
      align-items: center;
      margin-top: 12px;
    }
    .display-mode__label {
      font-size: 0.9rem;
      font-weight: 600;
      color: rgba(248, 250, 252, 0.85);
      margin-right: 4px;
    }
    .display-mode__button {
      appearance: none;
      border: 1px solid rgba(148, 163, 184, 0.35);
      background: rgba(15, 23, 42, 0.2);
      color: white;
      padding: 6px 14px;
      border-radius: 999px;
      font-weight: 600;
      cursor: pointer;
      transition: background 0.2s ease, transform 0.2s ease, border-color 0.2s ease;
    }
    .display-mode__button:hover,
    .display-mode__button:focus {
      background: rgba(37, 99, 235, 0.35);
      border-color: rgba(96, 165, 250, 0.75);
      outline: none;
    }
    .display-mode__button.is-active {
      background: white;
      color: var(--brand);
      border-color: transparent;
      box-shadow: 0 6px 18px rgba(14, 116, 244, 0.35);
      transform: translateY(-1px);
    }
    .layout {
      display: flex;
      gap: 32px;
      align-items: flex-start;
      max-width: 1320px;
      margin: -32px auto 48px;
      padding: 0 32px 64px;
    }
    .sidebar {
      position: sticky;
      top: 24px;
      flex: 0 0 300px;
      background: var(--bg-surface);
      border-radius: 20px;
      padding: 24px 20px;
      box-shadow: 0 24px 48px rgba(15, 23, 42, 0.12);
      border: 1px solid var(--border);
      display: flex;
      flex-direction: column;
      gap: 18px;
      height: fit-content;
      max-height: calc(100vh - 48px);
    }
    .preferences-card {
      background: linear-gradient(140deg, rgba(37, 99, 235, 0.08), rgba(2, 132, 199, 0.1));
      border-radius: 16px;
      padding: 18px 20px;
      border: 1px solid rgba(15, 23, 42, 0.08);
      display: flex;
      flex-direction: column;
      gap: 14px;
    }
    .preferences-card h2 {
      margin: 0;
      font-size: 1rem;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      color: var(--text-secondary);
    }
    .preferences-view {
      display: flex;
      flex-direction: column;
      gap: 12px;
    }
    .preferences-group {
      display: flex;
      flex-direction: column;
      gap: 6px;
    }
    .preferences-label {
      font-size: 0.85rem;
      font-weight: 600;
      color: var(--text-secondary);
    }
    .preferences-empty {
      font-size: 0.9rem;
      color: var(--text-secondary);
    }
    .preferences-edit {
      align-self: flex-start;
      padding: 6px 16px;
      border-radius: 10px;
      border: none;
      background: var(--brand);
      color: white;
      font-weight: 600;
      cursor: pointer;
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    .preferences-edit:hover,
    .preferences-edit:focus {
      transform: translateY(-1px);
      box-shadow: 0 8px 20px rgba(37, 99, 235, 0.25);
      outline: none;
    }
    .preferences-card textarea {
      width: 100%;
      min-height: 70px;
      resize: vertical;
      border-radius: 10px;
      border: 1px solid rgba(148, 163, 184, 0.4);
      padding: 10px 12px;
      font-size: 0.9rem;
      font-family: inherit;
      background: rgba(255, 255, 255, 0.82);
      color: var(--text-primary);
    }
    .preferences-actions {
      display: flex;
      gap: 10px;
      margin-top: 6px;
      flex-wrap: wrap;
    }
    .preferences-actions button {
      flex: 1 1 0;
      padding: 8px 12px;
      border-radius: 10px;
      border: none;
      font-weight: 600;
      cursor: pointer;
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    .preferences-actions button[type="submit"] {
      background: var(--brand);
      color: white;
      box-shadow: 0 10px 24px rgba(37, 99, 235, 0.32);
    }
    .preferences-actions button[type="submit"]:hover,
    .preferences-actions button[type="submit"]:focus {
      transform: translateY(-1px);
      outline: none;
    }
    .preferences-actions button.preferences-cancel,
    .preferences-actions button.preferences-reset {
      background: rgba(15, 23, 42, 0.08);
      color: var(--text-secondary);
    }
    .preferences-actions button.preferences-cancel:hover,
    .preferences-actions button.preferences-cancel:focus,
    .preferences-actions button.preferences-reset:hover,
    .preferences-actions button.preferences-reset:focus {
      background: rgba(15, 23, 42, 0.15);
      outline: none;
    }
    .preferences-status {
      min-height: 20px;
      font-size: 0.85rem;
      color: var(--text-secondary);
    }
    .nav-title {
      font-size: 0.9rem;
      font-weight: 700;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      color: var(--text-secondary);
      margin-top: 4px;
    }
    .sidebar nav {
      overflow-y: auto;
      padding-right: 6px;
      flex: 1;
    }
    .sidebar nav::-webkit-scrollbar {
      width: 6px;
    }
    .sidebar nav::-webkit-scrollbar-thumb {
      background: rgba(148, 163, 184, 0.5);
      border-radius: 999px;
    }
    .nav-list {
      list-style: none;
      padding-left: 0;
      margin: 0;
      display: flex;
      flex-direction: column;
      gap: 6px;
    }
    .nav-list.nav-level-2 {
      padding-left: 18px;
      gap: 4px;
    }
    .nav-list.nav-level-3 {
      padding-left: 18px;
      gap: 4px;
    }
    .nav-item a {
      display: block;
      padding: 8px 10px;
      border-radius: 10px;
      color: var(--text-secondary);
      text-decoration: none;
      transition: background 0.2s ease, color 0.2s ease;
    }
    .nav-item a:hover,
    .nav-item a:focus {
      background: var(--brand-soft);
      color: var(--brand);
      outline: none;
    }
    .nav-item a.is-active {
      background: var(--brand);
      color: white;
    }
    .content {
      flex: 1;
      min-width: 0;
    }
    .content-section {
      background: var(--bg-surface);
      border-radius: 24px;
      padding: 28px 32px;
      box-shadow: 0 24px 48px rgba(15, 23, 42, 0.08);
      border: 1px solid var(--border);
      margin-bottom: 36px;
      transition: box-shadow 0.25s ease, transform 0.25s ease;
      position: relative;
    }
    .content-section.is-hidden {
      display: none;
    }
    .content-section:not(.is-collapsed):hover {
      box-shadow: 0 28px 60px rgba(15, 23, 42, 0.12);
      transform: translateY(-2px);
    }
    .section-header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 16px;
      margin-bottom: 20px;
      flex-wrap: wrap;
    }
    .section-header h2 {
      margin: 0;
      font-size: 1.6rem;
    }
    .section-summary {
      margin: 0;
      font-size: 0.95rem;
      color: var(--text-secondary);
    }
    .section-toggle {
      appearance: none;
      border: none;
      background: var(--brand-soft);
      color: var(--brand);
      border-radius: 999px;
      font-weight: 600;
      padding: 6px 18px;
      cursor: pointer;
      transition: background 0.2s ease, transform 0.2s ease;
    }
    .section-toggle:hover,
    .section-toggle:focus {
      background: rgba(37, 99, 235, 0.2);
      outline: none;
      transform: translateY(-1px);
    }
    .section-body {
      display: flex;
      flex-direction: column;
      gap: 24px;
    }
    .content-section.is-collapsed .section-body {
      display: none;
    }
    .stats-grid {
      display: grid;
      gap: 20px;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
    }
    .stat-card {
      background: linear-gradient(145deg, rgba(37, 99, 235, 0.08), rgba(2, 132, 199, 0.08));
      border-radius: 18px;
      padding: 20px;
      border: 1px solid rgba(15, 23, 42, 0.08);
      display: flex;
      flex-direction: column;
      gap: 12px;
    }
    .stat-card h3 {
      font-size: 1rem;
      margin: 0;
      color: var(--text-secondary);
      text-transform: uppercase;
      letter-spacing: 0.08em;
    }
    .stat-card p {
      margin: 0;
      font-size: 1.1rem;
      font-weight: 600;
    }
    .stat-card ul {
      margin: 0;
      padding-left: 18px;
      color: var(--text-secondary);
      font-size: 0.95rem;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }
    .paper {
      background: var(--bg-surface);
      border-radius: 18px;
      padding: 22px 24px;
      border: 1px solid var(--border);
      box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.6);
      cursor: pointer;
      transition: border-color 0.2s ease, box-shadow 0.2s ease, transform 0.2s ease;
    }
    .paper + .paper {
      margin-top: 18px;
    }
    .paper h3 {
      margin: 0 0 12px 0;
      font-size: 1.2rem;
    }
    .paper h3 a {
      color: inherit;
      text-decoration: none;
    }
    .paper h3 a:hover {
      color: var(--brand);
    }
    .paper .meta {
      display: flex;
      flex-wrap: wrap;
      gap: 12px;
      font-size: 0.95rem;
      color: var(--text-secondary);
      margin-bottom: 10px;
    }
    .paper .meta .id {
      font-weight: 600;
      color: var(--brand);
    }
    .paper .subjects {
      font-size: 0.95rem;
      color: var(--text-secondary);
      margin-bottom: 12px;
    }
    .paper .abstract {
      color: var(--text-primary);
      margin-bottom: 16px;
    }
    .paper .links {
      display: flex;
      gap: 16px;
      font-weight: 600;
    }
    .paper .links a {
      color: var(--brand);
      text-decoration: none;
    }
    .paper .links a:hover {
      text-decoration: underline;
    }
    .paper:hover {
      box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.6), 0 12px 24px rgba(15, 23, 42, 0.12);
      transform: translateY(-1px);
    }
    .paper.paper--expanded {
      border-color: var(--brand);
      box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.6), 0 16px 32px rgba(37, 99, 235, 0.18);
    }
    body.display-mode-title .paper:not(.paper--expanded) .meta,
    body.display-mode-title .paper:not(.paper--expanded) .subjects,
    body.display-mode-title .paper:not(.paper--expanded) .abstract,
    body.display-mode-title .paper:not(.paper--expanded) .links {
      display: none;
    }
    body.display-mode-authors .paper:not(.paper--expanded) .meta .id {
      display: none;
    }
    body.display-mode-authors .paper:not(.paper--expanded) .subjects,
    body.display-mode-authors .paper:not(.paper--expanded) .abstract,
    body.display-mode-authors .paper:not(.paper--expanded) .links {
      display: none;
    }
    .empty-state {
      background: var(--bg-surface);
      border: 1px dashed var(--border);
      border-radius: 14px;
      padding: 18px 20px;
      color: var(--text-secondary);
    }
    .chip-set {
      display: flex;
      gap: 8px;
      flex-wrap: wrap;
      margin-top: 2px;
    }
    .chip {
      display: inline-flex;
      align-items: center;
      padding: 4px 12px;
      border-radius: 999px;
      background: var(--brand-soft);
      color: var(--brand);
      font-size: 0.85rem;
      font-weight: 600;
    }
    .watcher-summary {
      display: flex;
      flex-direction: column;
      gap: 6px;
      font-size: 0.93rem;
      color: var(--text-secondary);
    }
    .subject-grid {
      display: grid;
      gap: 28px;
      grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
    }
    .category-block {
      padding: 12px 0 4px;
      border-top: 1px solid rgba(148, 163, 184, 0.3);
    }
    .category-block:first-of-type {
      border-top: none;
      padding-top: 0;
    }
    .category-block__header {
      display: flex;
      align-items: baseline;
      gap: 12px;
      margin-bottom: 18px;
    }
    .category-block__header h3 {
      margin: 0;
      font-size: 1.35rem;
    }
    .subject-group {
      display: flex;
      flex-direction: column;
      gap: 14px;
      padding: 18px;
      border-radius: 16px;
      border: 1px solid rgba(148, 163, 184, 0.2);
      background: linear-gradient(145deg, rgba(255, 255, 255, 0.95), rgba(241, 245, 249, 0.6));
    }
    .subject-group__header {
      display: flex;
      align-items: baseline;
      gap: 12px;
    }
    .subject-group__header h4 {
      margin: 0;
      font-size: 1.05rem;
    }
    .count-chip {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      padding: 2px 10px;
      border-radius: 999px;
      background: var(--brand-soft);
      color: var(--brand);
      font-size: 0.85rem;
      font-weight: 600;
    }
    .skip-link {
      position: absolute;
      top: -48px;
      left: 16px;
      background: var(--brand);
      color: white;
      padding: 10px 16px;
      border-radius: 8px;
      text-decoration: none;
      font-weight: 600;
      transition: top 0.2s ease;
      z-index: 10;
    }
    .skip-link:focus {
      top: 16px;
    }
    footer {
      background: #0f172a;
      color: rgba(248, 250, 252, 0.9);
      padding: 24px 32px;
      font-size: 0.9rem;
      text-align: center;
    }
    footer a {
      color: #93c5fd;
      text-decoration: none;
    }
    footer a:hover {
      text-decoration: underline;
    }
    .noscript-warning {
      max-width: 960px;
      margin: 32px auto;
      padding: 20px;
      background: rgba(254, 240, 138, 0.35);
      border: 1px solid rgba(250, 204, 21, 0.6);
      border-radius: 12px;
      color: #92400e;
      font-size: 0.95rem;
    }
    @media (max-width: 960px) {
      .layout {
        flex-direction: column;
        padding: 0 20px 40px;
        gap: 24px;
      }
      .sidebar {
        position: static;
        width: 100%;
        max-height: none;
      }
      .content {
        width: 100%;
      }
      .nav-list {
        flex-direction: row;
        flex-wrap: wrap;
        gap: 8px;
      }
      .nav-list.nav-level-2,
      .nav-list.nav-level-3 {
        width: 100%;
        padding-left: 0;
      }
      .nav-list.nav-level-2 .nav-item a,
      .nav-list.nav-level-3 .nav-item a {
        padding-left: 14px;
      }
    }
    @media (max-width: 640px) {
      header .inner {
        padding: 0 20px;
      }
      .content-section {
        padding: 22px;
      }
      .stats-grid {
        grid-template-columns: 1fr;
      }
      .subject-grid {
        grid-template-columns: 1fr;
      }
      .layout {
        margin-top: -24px;
      }
      .preferences-actions {
        flex-direction: column;
      }
      .preferences-actions button {
        flex: 1 1 auto;
      }
      .source-switcher {
        justify-content: flex-start;
      }
      .display-mode {
        justify-content: flex-start;
      }
    }
  </style>
</head>
<body>
  <a class="skip-link" href="#main-content">Skip to content</a>
  <header>
    <div class="inner">
      <h1 class="page-title">arXiv cs Daily Digest</h1>
      <div class="page-meta">
        <span id="meta-source">Source: Computer Vision (cs.CV)</span>
        <span id="meta-date">Date: 2025-10-29</span>
        <span id="meta-generated">Generated at: 2025-10-29 12:16 CST</span>
        <span id="meta-total">Total papers: 89</span>
      </div>
      <div class="source-switcher" id="source-switcher" role="group" aria-label="Select arXiv category"></div>
      <div class="display-mode" id="display-mode-controls" role="group" aria-label="Select paper layout"></div>
    </div>
  </header>
  <noscript>
    <div class="noscript-warning">This dashboard requires JavaScript to filter sources and update preferences. Please enable JavaScript in your browser.</div>
  </noscript>
  <div class="layout">
    <aside class="sidebar">
      <div class="preferences-card">
        <h2>Tracking</h2>
        <div id="preferences-view" class="preferences-view">
          <div class="preferences-group">
            <span class="preferences-label">Favorite authors</span>
            <div class="chip-set" id="favorite-authors-view"></div>
          </div>
          <div class="preferences-group">
            <span class="preferences-label">Watched keywords</span>
            <div class="chip-set" id="keywords-view"></div>
          </div>
          <button type="button" id="edit-preferences" class="preferences-edit">Edit</button>
          <p class="preferences-status" id="preferences-status-view" role="status" aria-live="polite"></p>
        </div>
        <form id="preferences-form" hidden>
          <label for="favorite-authors-input" class="preferences-label">Favorite authors</label>
          <textarea id="favorite-authors-input" placeholder="One per line or comma separated">barron
Fei-Fei Li</textarea>
          <label for="keywords-input" class="preferences-label">Watched keywords</label>
          <textarea id="keywords-input" placeholder="One per line or comma separated">reconstruction
gaussian splatting</textarea>
          <div class="preferences-actions">
            <button type="submit">Save</button>
            <button type="button" id="cancel-preferences" class="preferences-cancel">Cancel</button>
            <button type="button" id="reset-preferences" class="preferences-reset">Reset</button>
          </div>
          <p class="preferences-status" id="preferences-status" role="status" aria-live="polite"></p>
        </form>
      </div>
      <div class="nav-title">On this page</div>
      <nav aria-label="Section navigation"></nav>
    </aside>
    <main id="main-content" class="content">
      <section id="overview" class="content-section is-collapsed is-hidden">
        <div class="section-header">
          <h2>All Papers</h2>
          <p class="section-summary" id="overview-summary"></p>
        </div>
        <div class="section-body" id="overview-body"></div>
      </section>
      <section id="stats" class="content-section" data-collapsible="true">
        <div class="section-header">
          <h2>Statistics</h2>
          <button type="button" class="section-toggle" data-target="stats" aria-expanded="true">Hide section</button>
        </div>
        <div class="section-body" id="stats-body"></div>
      </section>
      <section id="favorite" class="content-section is-collapsed is-hidden" data-collapsible="true">
        <div class="section-header">
          <h2>Favorite Authors</h2>
          <button type="button" class="section-toggle" data-target="favorite" aria-expanded="false">Show section</button>
        </div>
        <div class="section-body" id="favorite-body"></div>
      </section>
      <section id="keyword" class="content-section is-collapsed is-hidden" data-collapsible="true">
        <div class="section-header">
          <h2>Watched Keywords</h2>
          <button type="button" class="section-toggle" data-target="keyword" aria-expanded="false">Show section</button>
        </div>
        <div class="section-body" id="keywords-body"></div>
      </section>
      <section id="categories" class="content-section is-collapsed is-hidden" data-collapsible="true">
        <div class="section-header">
          <h2>Browse by Category</h2>
          <button type="button" class="section-toggle" data-target="categories" aria-expanded="false">Show section</button>
        </div>
        <div class="section-body" id="categories-body"></div>
      </section>
    </main>
  </div>
  <footer>
    Source: <a id="footer-source" href="https://arxiv.org/list/cs.CV/recent?skip=0&amp;show=2000" target="_blank" rel="noopener">Computer Vision (cs.CV)</a>
  </footer>
  <script type="application/json" id="digest-data">{"generated_at": "2025-10-29 12:16 CST", "sources": {"cs.CV": {"label": "Computer Vision (cs.CV)", "url": "https://arxiv.org/list/cs.CV/recent?skip=0&show=2000", "date": "2025-10-29", "articles": [{"arxiv_id": "arXiv:2510.24718", "title": "Generative View Stitching", "abs_url": "https://arxiv.org/abs/2510.24718", "pdf_url": "https://arxiv.org/pdf/2510.24718", "authors": ["Chonghyuk Song", "Michal Stary", "Boyuan Chen", "George Kopanas", "Vincent Sitzmann"], "abstract": "Title: Generative View Stitching", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24717", "title": "Uniform Discrete Diffusion with Metric Path for Video Generation", "abs_url": "https://arxiv.org/abs/2510.24717", "pdf_url": "https://arxiv.org/pdf/2510.24717", "authors": ["Haoge Deng", "Ting Pan", "Fan Zhang", "Yang Liu", "Zhuoyan Luo", "Yufeng Cui", "Wenxuan Wang", "Chunhua Shen", "Shiguang Shan", "Zhaoxiang Zhang", "Xinlong Wang"], "abstract": "Title: Uniform Discrete Diffusion with Metric Path for Video Generation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24711", "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance", "abs_url": "https://arxiv.org/abs/2510.24711", "pdf_url": "https://arxiv.org/pdf/2510.24711", "authors": ["Yujie Wei", "Shiwei Zhang", "Hangjie Yuan", "Yujin Han", "Zhekai Chen", "Jiayu Wang", "Difan Zou", "Xihui Liu", "Yingya Zhang", "Yu Liu", "Hongming Shan"], "abstract": "Title: Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24709", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?", "abs_url": "https://arxiv.org/abs/2510.24709", "pdf_url": "https://arxiv.org/pdf/2510.24709", "authors": ["Yihao Li", "Saeed Salehi", "Lyle Ungar", "Konrad P. Kording"], "abstract": "Title: Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Neurons and Cognition (q-bio.NC)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24688", "title": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection", "abs_url": "https://arxiv.org/abs/2510.24688", "pdf_url": "https://arxiv.org/pdf/2510.24688", "authors": ["Yun Zhang", "Zhaoliang Zheng", "Johnson Liu", "Zhiyu Huang", "Zewei Zhou", "Zonglin Meng", "Tianhui Cai", "Jiaqi Ma"], "abstract": "Title: MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24667", "title": "SAGE: Structure-Aware Generative Video Transitions between Diverse Clips", "abs_url": "https://arxiv.org/abs/2510.24667", "pdf_url": "https://arxiv.org/pdf/2510.24667", "authors": ["Mia Kan", "Yilin Liu", "Niloy Mitra"], "abstract": "Title: SAGE: Structure-Aware Generative Video Transitions between Diverse Clips", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24657", "title": "Group Relative Attention Guidance for Image Editing", "abs_url": "https://arxiv.org/abs/2510.24657", "pdf_url": "https://arxiv.org/pdf/2510.24657", "authors": ["Xuanpu Zhang", "Xuesong Niu", "Ruidong Chen", "Dan Song", "Jianhao Zeng", "Penghui Du", "Haoxiang Cao", "Kai Wu", "An-an Liu"], "abstract": "Title: Group Relative Attention Guidance for Image Editing", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24653", "title": "Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology", "abs_url": "https://arxiv.org/abs/2510.24653", "pdf_url": "https://arxiv.org/pdf/2510.24653", "authors": ["Veronica Thai", "Rui Li", "Meng Ling", "Shuning Jiang", "Jeremy Wolfe", "Raghu Machiraju", "Yan Hu", "Zaibo Li", "Anil Parwani", "Jian Chen"], "abstract": "Title: Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24640", "title": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries", "abs_url": "https://arxiv.org/abs/2510.24640", "pdf_url": "https://arxiv.org/pdf/2510.24640", "authors": ["Xin Zhang", "Yuqi Song", "Fei Zuo"], "abstract": "Title: A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24579", "title": "Physics-Inspired Gaussian Kolmogorov-Arnold Networks for X-ray Scatter Correction in Cone-Beam CT", "abs_url": "https://arxiv.org/abs/2510.24579", "pdf_url": "https://arxiv.org/pdf/2510.24579", "authors": ["Xu Jiang", "Huiying Pan", "Ligen Shi", "Jianing Sun", "Wenfeng Xu", "Xing Zhao"], "abstract": "Title: Physics-Inspired Gaussian Kolmogorov-Arnold Networks for X-ray Scatter Correction in Cone-Beam CT", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24563", "title": "OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents", "abs_url": "https://arxiv.org/abs/2510.24563", "pdf_url": "https://arxiv.org/pdf/2510.24563", "authors": ["Hongrui Jia", "Jitong Liao", "Xi Zhang", "Haiyang Xu", "Tianbao Xie", "Chaoya Jiang", "Ming Yan", "Si Liu", "Wei Ye", "Fei Huang"], "abstract": "Title: OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24514", "title": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs", "abs_url": "https://arxiv.org/abs/2510.24514", "pdf_url": "https://arxiv.org/pdf/2510.24514", "authors": ["Huanyu Zhang", "Wenshan Wu", "Chengzu Li", "Ning Shang", "Yan Xia", "Yangyu Huang", "Yifan Zhang", "Li Dong", "Zhang Zhang", "Liang Wang", "Tieniu Tan", "Furu Wei"], "abstract": "Title: Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24486", "title": "Fast and accurate neural reflectance transformation imaging through knowledge distillation", "abs_url": "https://arxiv.org/abs/2510.24486", "pdf_url": "https://arxiv.org/pdf/2510.24486", "authors": ["Tinsae G. Dulecha", "Leonardo Righetto", "Ruggero Pintus", "Enrico Gobbetti", "Andrea Giachetti"], "abstract": "Title: Fast and accurate neural reflectance transformation imaging through knowledge distillation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Graphics (cs.GR)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24474", "title": "Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated Sampling", "abs_url": "https://arxiv.org/abs/2510.24474", "pdf_url": "https://arxiv.org/pdf/2510.24474", "authors": ["Kyungmin Lee", "Sihyun Yu", "Jinwoo Shin"], "abstract": "Title: Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated Sampling", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24464", "title": "Kineo: Calibration-Free Metric Motion Capture From Sparse RGB Cameras", "abs_url": "https://arxiv.org/abs/2510.24464", "pdf_url": "https://arxiv.org/pdf/2510.24464", "authors": ["Charles Javerliat", "Pierre Raimbaud", "Guillaume Lavoué"], "abstract": "Title: Kineo: Calibration-Free Metric Motion Capture From Sparse RGB Cameras", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24456", "title": "A Critical Study towards the Detection of Parkinsons Disease using ML Technologies", "abs_url": "https://arxiv.org/abs/2510.24456", "pdf_url": "https://arxiv.org/pdf/2510.24456", "authors": ["Vivek Chetia", "Abdul Taher Khan", "Rahish Gogoi", "David Kapsian Khual", "Purnendu Bikash", "Sajal Saha"], "abstract": "Title: A Critical Study towards the Detection of Parkinsons Disease using ML Technologies", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24448", "title": "Rethinking Visual Intelligence: Insights from Video Pretraining", "abs_url": "https://arxiv.org/abs/2510.24448", "pdf_url": "https://arxiv.org/pdf/2510.24448", "authors": ["Pablo Acuaviva", "Aram Davtyan", "Mariam Hassan", "Sebastian Stapf", "Ahmad Rahimi", "Alexandre Alahi", "Paolo Favaro"], "abstract": "Title: Rethinking Visual Intelligence: Insights from Video Pretraining", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24437", "title": "Deeply-Conditioned Image Compression via Self-Generated Priors", "abs_url": "https://arxiv.org/abs/2510.24437", "pdf_url": "https://arxiv.org/pdf/2510.24437", "authors": ["Zhineng Zhao", "Zhihai He", "Zikun Zhou", "Siwei Ma", "Yaowei Wang"], "abstract": "Title: Deeply-Conditioned Image Compression via Self-Generated Priors", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24414", "title": "XAI Evaluation Framework for Semantic Segmentation", "abs_url": "https://arxiv.org/abs/2510.24414", "pdf_url": "https://arxiv.org/pdf/2510.24414", "authors": ["Reem Hammoud", "Abdul karim Gizzini", "Ali J. Ghandour"], "abstract": "Title: XAI Evaluation Framework for Semantic Segmentation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24413", "title": "50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir, Lebanon", "abs_url": "https://arxiv.org/abs/2510.24413", "pdf_url": "https://arxiv.org/pdf/2510.24413", "authors": ["Ali Ahmad Faour", "Nabil Amacha", "Ali J. Ghandour"], "abstract": "Title: 50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir, Lebanon", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24410", "title": "A Hybrid Approach for Visual Multi-Object Tracking", "abs_url": "https://arxiv.org/abs/2510.24410", "pdf_url": "https://arxiv.org/pdf/2510.24410", "authors": ["Toan Van Nguyen", "Rasmus G. K. Christiansen", "Dirk Kraft", "Leon Bodenhagen"], "abstract": "Title: A Hybrid Approach for Visual Multi-Object Tracking", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24399", "title": "GenTrack: A New Generation of Multi-Object Tracking", "abs_url": "https://arxiv.org/abs/2510.24399", "pdf_url": "https://arxiv.org/pdf/2510.24399", "authors": ["Toan Van Nguyen", "Rasmus G. K. Christiansen", "Dirk Kraft", "Leon Bodenhagen"], "abstract": "Title: GenTrack: A New Generation of Multi-Object Tracking", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24398", "title": "Unsupervised Detection of Post-Stroke Brain Abnormalities", "abs_url": "https://arxiv.org/abs/2510.24398", "pdf_url": "https://arxiv.org/pdf/2510.24398", "authors": ["Youwan Mahé", "Elise Bannier", "Stéphanie Leplaideur", "Elisa Fromont", "Francesca Galassi"], "abstract": "Title: Unsupervised Detection of Post-Stroke Brain Abnormalities", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24385", "title": "When are radiology reports useful for training medical image classifiers?", "abs_url": "https://arxiv.org/abs/2510.24385", "pdf_url": "https://arxiv.org/pdf/2510.24385", "authors": ["Herman Bergström", "Zhongqi Yue", "Fredrik D. Johansson"], "abstract": "Title: When are radiology reports useful for training medical image classifiers?", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24379", "title": "A Luminance-Aware Multi-Scale Network for Polarization Image Fusion with a Multi-Scene Dataset", "abs_url": "https://arxiv.org/abs/2510.24379", "pdf_url": "https://arxiv.org/pdf/2510.24379", "authors": ["Zhuangfan Huang", "Xiaosong Li", "Gao Wang", "Tao Ye", "Haishu Tan", "Huafeng Li"], "abstract": "Title: A Luminance-Aware Multi-Scale Network for Polarization Image Fusion with a Multi-Scene Dataset", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24378", "title": "Stroke Lesion Segmentation in Clinical Workflows: A Modular, Lightweight, and Deployment-Ready Tool", "abs_url": "https://arxiv.org/abs/2510.24378", "pdf_url": "https://arxiv.org/pdf/2510.24378", "authors": ["Yann Kerverdo", "Florent Leray", "Youwan Mahé", "Stéphanie Leplaideur", "Francesca Galassi"], "abstract": "Title: Stroke Lesion Segmentation in Clinical Workflows: A Modular, Lightweight, and Deployment-Ready Tool", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24374", "title": "Decoupling What to Count and Where to See for Referring Expression Counting", "abs_url": "https://arxiv.org/abs/2510.24374", "pdf_url": "https://arxiv.org/pdf/2510.24374", "authors": ["Yuda Zou", "Zijian Zhang", "Yongchao Xu"], "abstract": "Title: Decoupling What to Count and Where to See for Referring Expression Counting", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24366", "title": "Adaptive Knowledge Transferring with Switching Dual-Student Framework for Semi-Supervised Medical Image Segmentation", "abs_url": "https://arxiv.org/abs/2510.24366", "pdf_url": "https://arxiv.org/pdf/2510.24366", "authors": ["Thanh-Huy Nguyen", "Hoang-Thien Nguyen", "Ba-Thinh Lam", "Vi Vu", "Bach X. Nguyen", "Jianhua Xing", "Tianyang Wang", "Xingjian Li", "Min Xu"], "abstract": "Title: Adaptive Knowledge Transferring with Switching Dual-Student Framework for Semi-Supervised Medical Image Segmentation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24321", "title": "Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning", "abs_url": "https://arxiv.org/abs/2510.24321", "pdf_url": "https://arxiv.org/pdf/2510.24321", "authors": ["Ivica Dimitrovski", "Vlatko Spasev", "Ivan Kitanovski"], "abstract": "Title: Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24285", "title": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model", "abs_url": "https://arxiv.org/abs/2510.24285", "pdf_url": "https://arxiv.org/pdf/2510.24285", "authors": ["Juntian Zhang", "Song Jin", "Chuanqi Cheng", "Yuhan Liu", "Yankai Lin", "Xun Zhang", "Yufei Zhang", "Fei Jiang", "Guojun Yin", "Wei Lin", "Rui Yan"], "abstract": "Title: ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24278", "title": "Training-free Source Attribution of AI-generated Images via Resynthesis", "abs_url": "https://arxiv.org/abs/2510.24278", "pdf_url": "https://arxiv.org/pdf/2510.24278", "authors": ["Pietro Bongini", "Valentina Molinari", "Andrea Costanzo", "Benedetta Tondi", "Mauro Barni"], "abstract": "Title: Training-free Source Attribution of AI-generated Images via Resynthesis", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24262", "title": "UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level Task Adaptation", "abs_url": "https://arxiv.org/abs/2510.24262", "pdf_url": "https://arxiv.org/pdf/2510.24262", "authors": ["Jiyu Guo", "Shuo Yang", "Yiming Huang", "Yancheng Long", "Xiaobo Xia", "Xiu Su", "Bo Zhao", "Zeke Xie", "Liqiang Nie"], "abstract": "Title: UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level Task Adaptation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24260", "title": "DeshadowMamba: Deshadowing as 1D Sequential Similarity", "abs_url": "https://arxiv.org/abs/2510.24260", "pdf_url": "https://arxiv.org/pdf/2510.24260", "authors": ["Zhaotong Yang", "Yi Chen", "Yanying Li", "Shengfeng He", "Yangyang Xu", "Junyu Dong", "Jian Yang", "Yong Du"], "abstract": "Title: DeshadowMamba: Deshadowing as 1D Sequential Similarity", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24232", "title": "Delving into Cascaded Instability: A Lipschitz Continuity View on Image Restoration and Object Detection Synergy", "abs_url": "https://arxiv.org/abs/2510.24232", "pdf_url": "https://arxiv.org/pdf/2510.24232", "authors": ["Qing Zhao", "Weijian Deng", "Pengxu Wei", "ZiYi Dong", "Hannan Lu", "Xiangyang Ji", "Liang Lin"], "abstract": "Title: Delving into Cascaded Instability: A Lipschitz Continuity View on Image Restoration and Object Detection Synergy", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24231", "title": "Benchmarking Microsaccade Recognition with Event Cameras: A Novel Dataset and Evaluation", "abs_url": "https://arxiv.org/abs/2510.24231", "pdf_url": "https://arxiv.org/pdf/2510.24231", "authors": ["Waseem Shariff", "Timothy Hanley", "Maciej Stec", "Hossein Javidnia", "Peter Corcoran"], "abstract": "Title: Benchmarking Microsaccade Recognition with Event Cameras: A Novel Dataset and Evaluation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24214", "title": "SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs", "abs_url": "https://arxiv.org/abs/2510.24214", "pdf_url": "https://arxiv.org/pdf/2510.24214", "authors": ["Jinhong Deng", "Wen Li", "Joey Tianyi Zhou", "Yang He"], "abstract": "Title: SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24213", "title": "Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization", "abs_url": "https://arxiv.org/abs/2510.24213", "pdf_url": "https://arxiv.org/pdf/2510.24213", "authors": ["Haoxin Yang", "Yihong Lin", "Jingdan Kang", "Xuemiao Xu", "Yue Li", "Cheng Xu", "Shengfeng He"], "abstract": "Title: Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24211", "title": "MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration", "abs_url": "https://arxiv.org/abs/2510.24211", "pdf_url": "https://arxiv.org/pdf/2510.24211", "authors": ["Junhyuk So", "Hyunho Kook", "Chaeyeon Jang", "Eunhyeok Park"], "abstract": "Title: MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24202", "title": "CLFSeg: A Fuzzy-Logic based Solution for Boundary Clarity and Uncertainty Reduction in Medical Image Segmentation", "abs_url": "https://arxiv.org/abs/2510.24202", "pdf_url": "https://arxiv.org/pdf/2510.24202", "authors": ["Anshul Kaushal", "Kunal Jangid", "Vinod K. Kurmi"], "abstract": "Title: CLFSeg: A Fuzzy-Logic based Solution for Boundary Clarity and Uncertainty Reduction in Medical Image Segmentation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24195", "title": "Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2", "abs_url": "https://arxiv.org/abs/2510.24195", "pdf_url": "https://arxiv.org/pdf/2510.24195", "authors": ["Ziqi Zhou", "Yifan Hu", "Yufei Song", "Zijing Li", "Shengshan Hu", "Leo Yu Zhang", "Dezhong Yao", "Long Zheng", "Hai Jin"], "abstract": "Title: Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24152", "title": "Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning", "abs_url": "https://arxiv.org/abs/2510.24152", "pdf_url": "https://arxiv.org/pdf/2510.24152", "authors": ["Aodi Wu", "Xubo Luo"], "abstract": "Title: Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24136", "title": "MSRANetV2: An Explainable Deep Learning Architecture for Multi-class Classification of Colorectal Histopathological Images", "abs_url": "https://arxiv.org/abs/2510.24136", "pdf_url": "https://arxiv.org/pdf/2510.24136", "authors": ["Ovi Sarkar", "Md Shafiuzzaman", "Md. Faysal Ahamed", "Golam Mahmud", "Muhammad E. H. Chowdhury"], "abstract": "Title: MSRANetV2: An Explainable Deep Learning Architecture for Multi-class Classification of Colorectal Histopathological Images", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24134", "title": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "abs_url": "https://arxiv.org/abs/2510.24134", "pdf_url": "https://arxiv.org/pdf/2510.24134", "authors": ["Yang Du", "Zhuoran Lin", "Kaiqiang Song", "Biao Wang", "Zhicheng Zheng", "Tiezheng Ge", "Bo Zheng", "Qin Jin"], "abstract": "Title: VC4VG: Optimizing Video Captions for Text-to-Video Generation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24133", "title": "Compositional Image Synthesis with Inference-Time Scaling", "abs_url": "https://arxiv.org/abs/2510.24133", "pdf_url": "https://arxiv.org/pdf/2510.24133", "authors": ["Minsuk Ji", "Sanghyeok Lee", "Namhyuk Ahn"], "abstract": "Title: Compositional Image Synthesis with Inference-Time Scaling", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24129", "title": "ETC: training-free diffusion models acceleration with Error-aware Trend Consistency", "abs_url": "https://arxiv.org/abs/2510.24129", "pdf_url": "https://arxiv.org/pdf/2510.24129", "authors": ["Jiajian Xie", "Hubery Yin", "Chen Li", "Zhou Zhao", "Shengyu Zhang"], "abstract": "Title: ETC: training-free diffusion models acceleration with Error-aware Trend Consistency", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24117", "title": "DogMo: A Large-Scale Multi-View RGB-D Dataset for 4D Canine Motion Recovery", "abs_url": "https://arxiv.org/abs/2510.24117", "pdf_url": "https://arxiv.org/pdf/2510.24117", "authors": ["Zan Wang", "Siyu Chen", "Luya Mo", "Xinfeng Gao", "Yuxin Shen", "Lebin Ding", "Wei Liang"], "abstract": "Title: DogMo: A Large-Scale Multi-View RGB-D Dataset for 4D Canine Motion Recovery", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24116", "title": "UHKD: A Unified Framework for Heterogeneous Knowledge Distillation via Frequency-Domain Representations", "abs_url": "https://arxiv.org/abs/2510.24116", "pdf_url": "https://arxiv.org/pdf/2510.24116", "authors": ["Fengming Yu", "Haiwei Pan", "Kejia Zhang", "Jian Guan", "Haiying Jiang"], "abstract": "Title: UHKD: A Unified Framework for Heterogeneous Knowledge Distillation via Frequency-Domain Representations", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24105", "title": "Enhancing Pre-trained Representation Classifiability can Boost its Interpretability", "abs_url": "https://arxiv.org/abs/2510.24105", "pdf_url": "https://arxiv.org/pdf/2510.24105", "authors": ["Shufan Shen", "Zhaobo Qi", "Junshu Sun", "Qingming Huang", "Qi Tian", "Shuhui Wang"], "abstract": "Title: Enhancing Pre-trained Representation Classifiability can Boost its Interpretability", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24093", "title": "OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation", "abs_url": "https://arxiv.org/abs/2510.24093", "pdf_url": "https://arxiv.org/pdf/2510.24093", "authors": ["Agus Gunawan", "Samuel Teodoro", "Yun Chen", "Soo Ye Kim", "Jihyong Oh", "Munchurl Kim"], "abstract": "Title: OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24078", "title": "Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification", "abs_url": "https://arxiv.org/abs/2510.24078", "pdf_url": "https://arxiv.org/pdf/2510.24078", "authors": ["William Yang", "Xindi Wu", "Zhiwei Deng", "Esin Tureci", "Olga Russakovsky"], "abstract": "Title: Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24038", "title": "Enhancing CLIP Robustness via Cross-Modality Alignment", "abs_url": "https://arxiv.org/abs/2510.24038", "pdf_url": "https://arxiv.org/pdf/2510.24038", "authors": ["Xingyu Zhu", "Beier Zhu", "Shuo Wang", "Kesen Zhao", "Hanwang Zhang"], "abstract": "Title: Enhancing CLIP Robustness via Cross-Modality Alignment", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24037", "title": "Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models", "abs_url": "https://arxiv.org/abs/2510.24037", "pdf_url": "https://arxiv.org/pdf/2510.24037", "authors": ["Shufan Shen", "Junshu Sun", "Shuhui Wang", "Qingming Huang"], "abstract": "Title: Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24036", "title": "ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning", "abs_url": "https://arxiv.org/abs/2510.24036", "pdf_url": "https://arxiv.org/pdf/2510.24036", "authors": ["Xingyu Liu", "Kun Ming Goh"], "abstract": "Title: ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24034", "title": "AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts", "abs_url": "https://arxiv.org/abs/2510.24034", "pdf_url": "https://arxiv.org/pdf/2510.24034", "authors": ["Yufan Liu", "Wanqian Zhang", "Huashan Chen", "Lin Wang", "Xiaojun Jia", "Zheng Lin", "Weiping Wang"], "abstract": "Title: AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24010", "title": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks", "abs_url": "https://arxiv.org/abs/2510.24010", "pdf_url": "https://arxiv.org/pdf/2510.24010", "authors": ["Mirali Purohit", "Bimal Gajera", "Vatsal Malaviya", "Irish Mehta", "Kunal Kasodekar", "Jacob Adler", "Steven Lu", "Umaa Rebbapragada", "Hannah Kerner"], "abstract": "Title: Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24009", "title": "Towards the Automatic Segmentation, Modeling and Meshing of the Aortic Vessel Tree from Multicenter Acquisitions: An Overview of the SEG.A. 2023 Segmentation of the Aorta Challenge", "abs_url": "https://arxiv.org/abs/2510.24009", "pdf_url": "https://arxiv.org/pdf/2510.24009", "authors": ["Yuan Jin", "Antonio Pepe", "Gian Marco Melito", "Yuxuan Chen", "Yunsu Byeon", "Hyeseong Kim", "Kyungwon Kim", "Doohyun Park", "Euijoon Choi", "Dosik Hwang", "Andriy Myronenko", "Dong Yang", "Yufan He", "Daguang Xu", "Ayman El-Ghotni", "Mohamed Nabil", "Hossam El-Kady", "Ahmed Ayyad", "Amr Nasr", "Marek Wodzinski", "Henning Müller", "Hyeongyu Kim", "Yejee Shin", "Abbas Khan", "Muhammad Asad", "Alexander Zolotarev", "Caroline Roney", "Anthony Mathur", "Martin Benning", "Gregory Slabaugh", "Theodoros Panagiotis Vagenas", "Konstantinos Georgas", "George K. Matsopoulos", "Jihan Zhang", "Zhen Zhang", "Liqin Huang", "Christian Mayer", "Heinrich Mächler", "Jan Egger"], "abstract": "Title: Towards the Automatic Segmentation, Modeling and Meshing of the Aortic Vessel Tree from Multicenter Acquisitions: An Overview of the SEG.A. 2023 Segmentation of the Aorta Challenge", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24000", "title": "AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization", "abs_url": "https://arxiv.org/abs/2510.24000", "pdf_url": "https://arxiv.org/pdf/2510.24000", "authors": ["Heethanjan Kanagalingam", "Thenukan Pathmanathan", "Mokeeshan Vathanakumar", "Tharmakulasingam Mukunthan"], "abstract": "Title: AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23981", "title": "TeleEgo: Benchmarking Egocentric AI Assistants in the Wild", "abs_url": "https://arxiv.org/abs/2510.23981", "pdf_url": "https://arxiv.org/pdf/2510.23981", "authors": ["Jiaqi Yan", "Ruilong Ren", "Jingren Liu", "Shuning Xu", "Ling Wang", "Yiheng Wang", "Yun Wang", "Long Zhang", "Xiangyu Chen", "Changzhi Sun", "Jixiang Luo", "Dell Zhang", "Hao Sun", "Chi Zhang", "Xuelong Li"], "abstract": "Title: TeleEgo: Benchmarking Egocentric AI Assistants in the Wild", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23978", "title": "Efficient Cost-and-Quality Controllable Arbitrary-scale Super-resolution with Fourier Constraints", "abs_url": "https://arxiv.org/abs/2510.23978", "pdf_url": "https://arxiv.org/pdf/2510.23978", "authors": ["Kazutoshi Akita", "Norimichi Ukita"], "abstract": "Title: Efficient Cost-and-Quality Controllable Arbitrary-scale Super-resolution with Fourier Constraints", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23968", "title": "Reasoning Visual Language Model for Chest X-Ray Analysis", "abs_url": "https://arxiv.org/abs/2510.23968", "pdf_url": "https://arxiv.org/pdf/2510.23968", "authors": ["Andriy Myronenko", "Dong Yang", "Baris Turkbey", "Mariam Aboian", "Sena Azamat", "Esra Akcicek", "Hongxu Yin", "Pavlo Molchanov", "Marc Edgar", "Yufan He", "Pengfei Guo", "Yucheng Tang", "Daguang Xu"], "abstract": "Title: Reasoning Visual Language Model for Chest X-Ray Analysis", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23960", "title": "SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability", "abs_url": "https://arxiv.org/abs/2510.23960", "pdf_url": "https://arxiv.org/pdf/2510.23960", "authors": ["Peiyang Xu", "Minzhou Pan", "Zhaorun Chen", "Shuang Yang", "Chaowei Xiao", "Bo Li"], "abstract": "Title: SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23956", "title": "Neural USD: An object-centric framework for iterative editing and control", "abs_url": "https://arxiv.org/abs/2510.23956", "pdf_url": "https://arxiv.org/pdf/2510.23956", "authors": ["Alejandro Escontrela", "Shrinu Kushagra", "Sjoerd van Steenkiste", "Yulia Rubanova", "Aleksander Holynski", "Kelsey Allen", "Kevin Murphy", "Thomas Kipf"], "abstract": "Title: Neural USD: An object-centric framework for iterative editing and control", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23943", "title": "Adaptive Training of INRs via Pruning and Densification", "abs_url": "https://arxiv.org/abs/2510.23943", "pdf_url": "https://arxiv.org/pdf/2510.23943", "authors": ["Diana Aldana", "João Paulo Lima", "Daniel Csillag", "Daniel Perazzo", "Haoan Feng", "Luiz Velho", "Tiago Novello"], "abstract": "Title: Adaptive Training of INRs via Pruning and Densification", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23930", "title": "PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors", "abs_url": "https://arxiv.org/abs/2510.23930", "pdf_url": "https://arxiv.org/pdf/2510.23930", "authors": ["Xirui Jin", "Renbiao Jin", "Boying Li", "Danping Zou", "Wenxian Yu"], "abstract": "Title: PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23929", "title": "TurboPortrait3D: Single-step diffusion-based fast portrait novel-view synthesis", "abs_url": "https://arxiv.org/abs/2510.23929", "pdf_url": "https://arxiv.org/pdf/2510.23929", "authors": ["Emily Kim", "Julieta Martinez", "Timur Bagautdinov", "Jessica Hodgins"], "abstract": "Title: TurboPortrait3D: Single-step diffusion-based fast portrait novel-view synthesis", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23907", "title": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning", "abs_url": "https://arxiv.org/abs/2510.23907", "pdf_url": "https://arxiv.org/pdf/2510.23907", "authors": ["Eddison Pham", "Prisha Priyadarshini", "Adrian Maliackel", "Kanishk Bandi", "Cristian Meo", "Kevin Zhu"], "abstract": "Title: DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23894", "title": "Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation", "abs_url": "https://arxiv.org/abs/2510.23894", "pdf_url": "https://arxiv.org/pdf/2510.23894", "authors": ["Jinxin Zhou", "Jiachen Jiang", "Zhihui Zhu"], "abstract": "Title: Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23880", "title": "TRELLISWorld: Training-Free World Generation from Object Generators", "abs_url": "https://arxiv.org/abs/2510.23880", "pdf_url": "https://arxiv.org/pdf/2510.23880", "authors": ["Hanke Chen", "Yuan Liu", "Minchen Li"], "abstract": "Title: TRELLISWorld: Training-Free World Generation from Object Generators", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Graphics (cs.GR)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23816", "title": "RareFlow: Physics-Aware Flow-Matching for Cross-Sensor Super-Resolution of Rare-Earth Features", "abs_url": "https://arxiv.org/abs/2510.23816", "pdf_url": "https://arxiv.org/pdf/2510.23816", "authors": ["Forouzan Fallah", "Wenwen Li", "Chia-Yu Hsu", "Hyunho Lee", "Yezhou Yang"], "abstract": "Title: RareFlow: Physics-Aware Flow-Matching for Cross-Sensor Super-Resolution of Rare-Earth Features", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23798", "title": "A geometric and deep learning reproducible pipeline for monitoring floating anthropogenic debris in urban rivers using in situ cameras", "abs_url": "https://arxiv.org/abs/2510.23798", "pdf_url": "https://arxiv.org/pdf/2510.23798", "authors": ["Gauthier Grimmer", "Romain Wenger", "Clément Flint", "Germain Forestier", "Gilles Rixhon", "Valentin Chardon"], "abstract": "Title: A geometric and deep learning reproducible pipeline for monitoring floating anthropogenic debris in urban rivers using in situ cameras", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23785", "title": "CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting", "abs_url": "https://arxiv.org/abs/2510.23785", "pdf_url": "https://arxiv.org/pdf/2510.23785", "authors": ["Md Tanvir Hossain", "Akif Islam", "Mohd Ruhul Ameen"], "abstract": "Title: CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23775", "title": "Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices", "abs_url": "https://arxiv.org/abs/2510.23775", "pdf_url": "https://arxiv.org/pdf/2510.23775", "authors": ["Aryan Mathur", "Asaduddin Ahmed", "Pushti Amit Vasoya", "Simeon Kandan Sonar", "Yasir Z", "Madesh Kuppusamy"], "abstract": "Title: Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Image and Video Processing (eess.IV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24623", "title": "GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization", "abs_url": "https://arxiv.org/abs/2510.24623", "pdf_url": "https://arxiv.org/pdf/2510.24623", "authors": ["Nicolai Steinke", "Daniel Goehring"], "abstract": "Title: GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24503", "title": "Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "abs_url": "https://arxiv.org/abs/2510.24503", "pdf_url": "https://arxiv.org/pdf/2510.24503", "authors": ["Mortesa Hussaini", "Jan Theiß", "Anthony Stein"], "abstract": "Title: Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "primary_subject": "Machine Learning (cs.LG)", "subjects": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Multiagent Systems (cs.MA)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24446", "title": "SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space", "abs_url": "https://arxiv.org/abs/2510.24446", "pdf_url": "https://arxiv.org/pdf/2510.24446", "authors": ["Viktoriia Zinkovich", "Anton Antonov", "Andrei Spiridonov", "Denis Shepelev", "Andrey Moskalenko", "Daria Pugacheva", "Elena Tutubalina", "Andrey Kuznetsov", "Vlad Shakhuro"], "abstract": "Title: SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space", "primary_subject": "Computation and Language (cs.CL)", "subjects": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24411", "title": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows", "abs_url": "https://arxiv.org/abs/2510.24411", "pdf_url": "https://arxiv.org/pdf/2510.24411", "authors": ["Qiushi Sun", "Mukai Li", "Zhoumianze Liu", "Zhihui Xie", "Fangzhi Xu", "Zhangyue Yin", "Kanzhi Cheng", "Zehao Li", "Zichen Ding", "Qi Liu", "Zhiyong Wu", "Zhuosheng Zhang", "Ben Kao", "Lingpeng Kong"], "abstract": "Title: OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows", "primary_subject": "Artificial Intelligence (cs.AI)", "subjects": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24335", "title": "NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation", "abs_url": "https://arxiv.org/abs/2510.24335", "pdf_url": "https://arxiv.org/pdf/2510.24335", "authors": ["Mingyu Jeong", "Eunsung Kim", "Sehun Park", "Andrew Jaeyong Choi"], "abstract": "Title: NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24332", "title": "Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes", "abs_url": "https://arxiv.org/abs/2510.24332", "pdf_url": "https://arxiv.org/pdf/2510.24332", "authors": ["Jonas Hein", "Lazaros Vlachopoulos", "Maurits Geert Laurent Olthof", "Bastian Sigrist", "Philipp Fürnstahl", "Matthias Seibold"], "abstract": "Title: Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes", "primary_subject": "Sound (cs.SD)", "subjects": ["Sound (cs.SD)", "Computer Vision and Pattern Recognition (cs.CV)", "Audio and Speech Processing (eess.AS)", "Image and Video Processing (eess.IV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24331", "title": "What do vision-language models see in the context? Investigating multimodal in-context learning", "abs_url": "https://arxiv.org/abs/2510.24331", "pdf_url": "https://arxiv.org/pdf/2510.24331", "authors": ["Gabriel O. dos Santos", "Esther Colombini", "Sandra Avila"], "abstract": "Title: What do vision-language models see in the context? Investigating multimodal in-context learning", "primary_subject": "Machine Learning (cs.LG)", "subjects": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24261", "title": "DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation", "abs_url": "https://arxiv.org/abs/2510.24261", "pdf_url": "https://arxiv.org/pdf/2510.24261", "authors": ["Jingyi Tian", "Le Wang", "Sanping Zhou", "Sen Wang", "Jiayi Li", "Gang Hua"], "abstract": "Title: DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24108", "title": "ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring", "abs_url": "https://arxiv.org/abs/2510.24108", "pdf_url": "https://arxiv.org/pdf/2510.24108", "authors": ["Zhenxin Li", "Wenhao Yao", "Zi Wang", "Xinglong Sun", "Jingde Chen", "Nadine Chang", "Maying Shen", "Jingyu Song", "Zuxuan Wu", "Shiyi Lan", "Jose M. Alvarez"], "abstract": "Title: ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24024", "title": "Listening without Looking: Modality Bias in Audio-Visual Captioning", "abs_url": "https://arxiv.org/abs/2510.24024", "pdf_url": "https://arxiv.org/pdf/2510.24024", "authors": ["Yuchi Ishikawa", "Toranosuke Manabe", "Tatsuya Komatsu", "Yoshimitsu Aoki"], "abstract": "Title: Listening without Looking: Modality Bias in Audio-Visual Captioning", "primary_subject": "Audio and Speech Processing (eess.AS)", "subjects": ["Audio and Speech Processing (eess.AS)", "Computer Vision and Pattern Recognition (cs.CV)", "Image and Video Processing (eess.IV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23977", "title": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling", "abs_url": "https://arxiv.org/abs/2510.23977", "pdf_url": "https://arxiv.org/pdf/2510.23977", "authors": ["Yohan Abeysinghe", "Muhammad Akhtar Munir", "Sanoojan Baliah", "Ron Sarafian", "Fahad Shahbaz Khan", "Yinon Rudich", "Salman Khan"], "abstract": "Title: Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling", "primary_subject": "Machine Learning (cs.LG)", "subjects": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23928", "title": "Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments", "abs_url": "https://arxiv.org/abs/2510.23928", "pdf_url": "https://arxiv.org/pdf/2510.23928", "authors": ["Raman Jha", "Yang Zhou", "Giuseppe Loianno"], "abstract": "Title: Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23807", "title": "Why Foundation Models in Pathology Are Failing", "abs_url": "https://arxiv.org/abs/2510.23807", "pdf_url": "https://arxiv.org/pdf/2510.23807", "authors": ["Hamid R. Tizhoosh"], "abstract": "Title: Why Foundation Models in Pathology Are Failing", "primary_subject": "Artificial Intelligence (cs.AI)", "subjects": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23763", "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "abs_url": "https://arxiv.org/abs/2510.23763", "pdf_url": "https://arxiv.org/pdf/2510.23763", "authors": ["Siyin Wang", "Jinlan Fu", "Feihong Liu", "Xinzhe He", "Huangxuan Wu", "Junhao Shi", "Kexin Huang", "Zhaoye Fei", "Jingjing Gong", "Zuxuan Wu", "Yugang Jiang", "See-Kiong Ng", "Tat-Seng Chua", "Xipeng Qiu"], "abstract": "Title: RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23660", "title": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "abs_url": "https://arxiv.org/abs/2510.23660", "pdf_url": "https://arxiv.org/pdf/2510.23660", "authors": ["Gazi Tanbhir", "Md. Farhan Shahriyar", "Abdullah Md Raihan Chy"], "abstract": "Title: Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "primary_subject": "Machine Learning (cs.LG)", "subjects": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23659", "title": "Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine", "abs_url": "https://arxiv.org/abs/2510.23659", "pdf_url": "https://arxiv.org/pdf/2510.23659", "authors": ["Md. Farhan Shahriyar", "Gazi Tanbhir", "Abdullah Md Raihan Chy"], "abstract": "Title: Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine", "primary_subject": "Machine Learning (cs.LG)", "subjects": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)", "Emerging Technologies (cs.ET)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23633", "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "abs_url": "https://arxiv.org/abs/2510.23633", "pdf_url": "https://arxiv.org/pdf/2510.23633", "authors": ["Xun Su", "Hiroyuki Kasai"], "abstract": "Title: Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "primary_subject": "Machine Learning (cs.LG)", "subjects": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Image and Video Processing (eess.IV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}], "stats": {"total": 89, "total_authorships": 550, "unique_authors": 529, "section_counts": {"Authors and titles": 89}, "top_authors": [["Ali J. Ghandour", 2], ["Toan Van Nguyen", 2], ["Rasmus G. K. Christiansen", 2], ["Dirk Kraft", 2], ["Leon Bodenhagen", 2]], "top_phrases": [["generated images", 4], ["3d gaussian splatting guided", 2], ["4d canine motion recovery", 2]], "average_authors": 6.179775280898877}}, "cs.RO": {"label": "Robotics (cs.RO)", "url": "https://arxiv.org/list/cs.RO/recent?skip=0&show=2000", "date": "2025-10-29", "articles": [{"arxiv_id": "arXiv:2510.24692", "title": "Embodying Physical Computing into Soft Robots", "abs_url": "https://arxiv.org/abs/2510.24692", "pdf_url": "https://arxiv.org/pdf/2510.24692", "authors": ["Jun Wang", "Ziyang Zhou", "Ardalan Kahak", "Suyi Li"], "abstract": "Title: Embodying Physical Computing into Soft Robots", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24683", "title": "A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers", "abs_url": "https://arxiv.org/abs/2510.24683", "pdf_url": "https://arxiv.org/pdf/2510.24683", "authors": ["Caleb Escobedo", "Nataliya Nechyporenko", "Shreyas Kadekodi", "Alessandro Roncone"], "abstract": "Title: A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24680", "title": "Fare: Failure Resilience in Learned Visual Navigation Control", "abs_url": "https://arxiv.org/abs/2510.24680", "pdf_url": "https://arxiv.org/pdf/2510.24680", "authors": ["Zishuo Wang", "Joel Loo", "David Hsu"], "abstract": "Title: Fare: Failure Resilience in Learned Visual Navigation Control", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24676", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing Control of Powered Transfemoral Prosthesis", "abs_url": "https://arxiv.org/abs/2510.24676", "pdf_url": "https://arxiv.org/pdf/2510.24676", "authors": ["Jiaxuan Zhang", "Yuquan Leng", "Yixuan Guo", "Chenglong Fu"], "abstract": "Title: Feature Matching-Based Gait Phase Prediction for Obstacle Crossing Control of Powered Transfemoral Prosthesis", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Systems and Control (eess.SY)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24671", "title": "Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder", "abs_url": "https://arxiv.org/abs/2510.24671", "pdf_url": "https://arxiv.org/pdf/2510.24671", "authors": ["Li Li", "Tobias Brinkmann", "Till Temmen", "Markus Eisenbarth", "Jakob Andert"], "abstract": "Title: Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24623", "title": "GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization", "abs_url": "https://arxiv.org/abs/2510.24623", "pdf_url": "https://arxiv.org/pdf/2510.24623", "authors": ["Nicolai Steinke", "Daniel Goehring"], "abstract": "Title: GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24584", "title": "Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning", "abs_url": "https://arxiv.org/abs/2510.24584", "pdf_url": "https://arxiv.org/pdf/2510.24584", "authors": ["Jørgen Anker Olsen", "Lars Rønhaug Pettersen", "Kostas Alexis"], "abstract": "Title: Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24571", "title": "Spatiotemporal Calibration of Doppler Velocity Logs for Underwater Robots", "abs_url": "https://arxiv.org/abs/2510.24571", "pdf_url": "https://arxiv.org/pdf/2510.24571", "authors": ["Hongxu Zhao", "Guangyang Zeng", "Yunling Shao", "Tengfei Zhang", "Junfeng Wu"], "abstract": "Title: Spatiotemporal Calibration of Doppler Velocity Logs for Underwater Robots", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24554", "title": "An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments", "abs_url": "https://arxiv.org/abs/2510.24554", "pdf_url": "https://arxiv.org/pdf/2510.24554", "authors": ["Vignesh Kottayam Viswanathan", "Yifan Bai", "Scott Fredriksson", "Sumeet Satpute", "Christoforos Kanellakis", "George Nikolakopoulos"], "abstract": "Title: An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24533", "title": "GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater Robots", "abs_url": "https://arxiv.org/abs/2510.24533", "pdf_url": "https://arxiv.org/pdf/2510.24533", "authors": ["Yuan Shen", "Yuze Hong", "Guangyang Zeng", "Tengfei Zhang", "Pui Yi Chui", "Ziyang Hong", "Junfeng Wu"], "abstract": "Title: GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater Robots", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24515", "title": "Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems", "abs_url": "https://arxiv.org/abs/2510.24515", "pdf_url": "https://arxiv.org/pdf/2510.24515", "authors": ["Malintha Fernando", "Petter Ögren", "Silun Zhang"], "abstract": "Title: Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24508", "title": "Supervisory Measurement-Guided Noise Covariance Estimation", "abs_url": "https://arxiv.org/abs/2510.24508", "pdf_url": "https://arxiv.org/pdf/2510.24508", "authors": ["Haoying Li", "Yifan Peng", "Junfeng Wu"], "abstract": "Title: Supervisory Measurement-Guided Noise Covariance Estimation", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24457", "title": "Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance", "abs_url": "https://arxiv.org/abs/2510.24457", "pdf_url": "https://arxiv.org/pdf/2510.24457", "authors": ["Jorge Vicente-Martinez (1)", "Edgar Ramirez-Laboreo (1) ((1) Universidad de Zaragoza)"], "abstract": "Title: Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Systems and Control (eess.SY)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24335", "title": "NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation", "abs_url": "https://arxiv.org/abs/2510.24335", "pdf_url": "https://arxiv.org/pdf/2510.24335", "authors": ["Mingyu Jeong", "Eunsung Kim", "Sehun Park", "Andrew Jaeyong Choi"], "abstract": "Title: NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24315", "title": "Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground Cooperation", "abs_url": "https://arxiv.org/abs/2510.24315", "pdf_url": "https://arxiv.org/pdf/2510.24315", "authors": ["Baozhe Zhang", "Xinwei Chen", "Qingcheng Chen", "Chao Xu", "Fei Gao", "Yanjun Cao"], "abstract": "Title: Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground Cooperation", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24261", "title": "DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation", "abs_url": "https://arxiv.org/abs/2510.24261", "pdf_url": "https://arxiv.org/pdf/2510.24261", "authors": ["Jingyi Tian", "Le Wang", "Sanping Zhou", "Sen Wang", "Jiayi Li", "Gang Hua"], "abstract": "Title: DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24257", "title": "Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors", "abs_url": "https://arxiv.org/abs/2510.24257", "pdf_url": "https://arxiv.org/pdf/2510.24257", "authors": ["Ziqi Ma", "Changda Tian", "Yue Gao"], "abstract": "Title: Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24194", "title": "Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames", "abs_url": "https://arxiv.org/abs/2510.24194", "pdf_url": "https://arxiv.org/pdf/2510.24194", "authors": ["Ev Zisselman", "Mirco Mutti", "Shelly Francis-Meretzki", "Elisei Shafer", "Aviv Tamar"], "abstract": "Title: Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Machine Learning (cs.LG)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24118", "title": "LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation", "abs_url": "https://arxiv.org/abs/2510.24118", "pdf_url": "https://arxiv.org/pdf/2510.24118", "authors": ["Haotian Zhou", "Xiaole Wang", "He Li", "Fusheng Sun", "Shengyu Guo", "Guolei Qi", "Jianghuan Xu", "Huijing Zhao"], "abstract": "Title: LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24109", "title": "PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI", "abs_url": "https://arxiv.org/abs/2510.24109", "pdf_url": "https://arxiv.org/pdf/2510.24109", "authors": ["Wenbin Ding", "Jun Chen", "Mingjia Chen", "Fei Xie", "Qi Mao", "Philip Dames"], "abstract": "Title: PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24108", "title": "ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring", "abs_url": "https://arxiv.org/abs/2510.24108", "pdf_url": "https://arxiv.org/pdf/2510.24108", "authors": ["Zhenxin Li", "Wenhao Yao", "Zi Wang", "Xinglong Sun", "Jingde Chen", "Nadine Chang", "Maying Shen", "Jingyu Song", "Zuxuan Wu", "Shiyi Lan", "Jose M. Alvarez"], "abstract": "Title: ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24069", "title": "Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition", "abs_url": "https://arxiv.org/abs/2510.24069", "pdf_url": "https://arxiv.org/pdf/2510.24069", "authors": ["Sangmin Kim", "Hajun Kim", "Gijeong Kim", "Min-Gyu Kim", "Hae-Won Park"], "abstract": "Title: Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24067", "title": "Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition", "abs_url": "https://arxiv.org/abs/2510.24067", "pdf_url": "https://arxiv.org/pdf/2510.24067", "authors": ["Tianyi Ding", "Ronghao Zheng", "Senlin Zhang", "Meiqin Liu"], "abstract": "Title: Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24055", "title": "Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation", "abs_url": "https://arxiv.org/abs/2510.24055", "pdf_url": "https://arxiv.org/pdf/2510.24055", "authors": ["Xiucheng Zhang", "Yang Jiang", "Hongwei Qing", "Jiashuo Bai"], "abstract": "Title: Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Machine Learning (cs.LG)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24052", "title": "SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration", "abs_url": "https://arxiv.org/abs/2510.24052", "pdf_url": "https://arxiv.org/pdf/2510.24052", "authors": ["Jongsuk Kim", "Jaeyoung Lee", "Gyojin Han", "Dongjae Lee", "Minki Jeong", "Junmo Kim"], "abstract": "Title: SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24029", "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model", "abs_url": "https://arxiv.org/abs/2510.24029", "pdf_url": "https://arxiv.org/pdf/2510.24029", "authors": ["Andrew Gerstenslager", "Bekarys Dukenbaev", "Ali A. Minai"], "abstract": "Title: Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)", "Neurons and Cognition (q-bio.NC)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23997", "title": "VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion", "abs_url": "https://arxiv.org/abs/2510.23997", "pdf_url": "https://arxiv.org/pdf/2510.23997", "authors": ["Stanley Wu", "Mohamad H. Danesh", "Simon Li", "Hanna Yurchyk", "Amin Abyaneh", "Anas El Houssaini", "David Meger", "Hsiu-Chin Lin"], "abstract": "Title: VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23988", "title": "A Survey on Collaborative SLAM with 3D Gaussian Splatting", "abs_url": "https://arxiv.org/abs/2510.23988", "pdf_url": "https://arxiv.org/pdf/2510.23988", "authors": ["Phuc Nguyen Xuan", "Thanh Nguyen Canh", "Huu-Hung Nguyen", "Nak Young Chong", "Xiem HoangVan"], "abstract": "Title: A Survey on Collaborative SLAM with 3D Gaussian Splatting", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23963", "title": "Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping", "abs_url": "https://arxiv.org/abs/2510.23963", "pdf_url": "https://arxiv.org/pdf/2510.23963", "authors": ["Hiroki Ishikawa", "Kyosuke Ishibashi", "Ko Yamamoto"], "abstract": "Title: Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23954", "title": "A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots with Multiple Tubes and Tendons", "abs_url": "https://arxiv.org/abs/2510.23954", "pdf_url": "https://arxiv.org/pdf/2510.23954", "authors": ["Pejman Kheradmand", "Behnam Moradkhani", "Raghavasimhan Sankaranarayanan", "Kent K. Yamamoto", "Tanner J. Zachem", "Patrick J. Codd", "Yash Chitalia", "Pierre E. Dupont"], "abstract": "Title: A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots with Multiple Tubes and Tendons", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23928", "title": "Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments", "abs_url": "https://arxiv.org/abs/2510.23928", "pdf_url": "https://arxiv.org/pdf/2510.23928", "authors": ["Raman Jha", "Yang Zhou", "Giuseppe Loianno"], "abstract": "Title: Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23902", "title": "Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped", "abs_url": "https://arxiv.org/abs/2510.23902", "pdf_url": "https://arxiv.org/pdf/2510.23902", "authors": ["Jans Solano", "Diego Quiroz"], "abstract": "Title: Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23860", "title": "Motivating Students' Self-study with Goal Reminder and Emotional Support", "abs_url": "https://arxiv.org/abs/2510.23860", "pdf_url": "https://arxiv.org/pdf/2510.23860", "authors": ["Hyung Chan Cho", "Go-Eum Cha", "Yanfu Liu", "Sooyeon Jeong"], "abstract": "Title: Motivating Students' Self-study with Goal Reminder and Emotional Support", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23763", "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "abs_url": "https://arxiv.org/abs/2510.23763", "pdf_url": "https://arxiv.org/pdf/2510.23763", "authors": ["Siyin Wang", "Jinlan Fu", "Feihong Liu", "Xinzhe He", "Huangxuan Wu", "Junhao Shi", "Kexin Huang", "Zhaoye Fei", "Jingjing Gong", "Zuxuan Wu", "Yugang Jiang", "See-Kiong Ng", "Tat-Seng Chua", "Xipeng Qiu"], "abstract": "Title: RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "primary_subject": "Robotics (cs.RO)", "subjects": ["Robotics (cs.RO)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24482", "title": "Sample-efficient and Scalable Exploration in Continuous-Time RL", "abs_url": "https://arxiv.org/abs/2510.24482", "pdf_url": "https://arxiv.org/pdf/2510.24482", "authors": ["Klemens Iten", "Lenart Treven", "Bhavya Sukhija", "Florian Dörfler", "Andreas Krause"], "abstract": "Title: Sample-efficient and Scalable Exploration in Continuous-Time RL", "primary_subject": "Machine Learning (cs.LG)", "subjects": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24461", "title": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks", "abs_url": "https://arxiv.org/abs/2510.24461", "pdf_url": "https://arxiv.org/pdf/2510.24461", "authors": ["Korneel Van den Berghe", "Stein Stroobants", "Vijay Janapa Reddi", "G.C.H.E. de Croon"], "abstract": "Title: Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks", "primary_subject": "Artificial Intelligence (cs.AI)", "subjects": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24410", "title": "A Hybrid Approach for Visual Multi-Object Tracking", "abs_url": "https://arxiv.org/abs/2510.24410", "pdf_url": "https://arxiv.org/pdf/2510.24410", "authors": ["Toan Van Nguyen", "Rasmus G. K. Christiansen", "Dirk Kraft", "Leon Bodenhagen"], "abstract": "Title: A Hybrid Approach for Visual Multi-Object Tracking", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24399", "title": "GenTrack: A New Generation of Multi-Object Tracking", "abs_url": "https://arxiv.org/abs/2510.24399", "pdf_url": "https://arxiv.org/pdf/2510.24399", "authors": ["Toan Van Nguyen", "Rasmus G. K. Christiansen", "Dirk Kraft", "Leon Bodenhagen"], "abstract": "Title: GenTrack: A New Generation of Multi-Object Tracking", "primary_subject": "Computer Vision and Pattern Recognition (cs.CV)", "subjects": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24259", "title": "Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?", "abs_url": "https://arxiv.org/abs/2510.24259", "pdf_url": "https://arxiv.org/pdf/2510.24259", "authors": ["Ziqi Ma", "Sao Mai Nguyen", "Philippe Xu"], "abstract": "Title: Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?", "primary_subject": "Computation and Language (cs.CL)", "subjects": ["Computation and Language (cs.CL)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24161", "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "abs_url": "https://arxiv.org/abs/2510.24161", "pdf_url": "https://arxiv.org/pdf/2510.24161", "authors": ["Wentao Tan", "Bowen Wang", "Heng Zhi", "Chenyu Liu", "Zhe Li", "Jian Liu", "Zengrong Lin", "Yukun Dai", "Yipeng Chen", "Wenjie Yang", "Enci Xie", "Hao Xue", "Baixu Ji", "Chen Xu", "Zhibin Wang", "Tianshi Wang", "Lei Zhu", "Heng Tao Shen"], "abstract": "Title: BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "primary_subject": "Artificial Intelligence (cs.AI)", "subjects": ["Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.24095", "title": "Learning Parameterized Skills from Demonstrations", "abs_url": "https://arxiv.org/abs/2510.24095", "pdf_url": "https://arxiv.org/pdf/2510.24095", "authors": ["Vedant Gupta", "Haotian Fu", "Calvin Luo", "Yiding Jiang", "George Konidaris"], "abstract": "Title: Learning Parameterized Skills from Demonstrations", "primary_subject": "Machine Learning (cs.LG)", "subjects": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23899", "title": "Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments", "abs_url": "https://arxiv.org/abs/2510.23899", "pdf_url": "https://arxiv.org/pdf/2510.23899", "authors": ["Maria G. Mendoza", "Addison Kalanther", "Daniel Bostwick", "Emma Stephan", "Chinmay Maheshwari", "Shankar Sastry"], "abstract": "Title: Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments", "primary_subject": "Multiagent Systems (cs.MA)", "subjects": ["Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23895", "title": "Modeling and Scheduling of Fusion Patterns in Autonomous Driving Systems (Extended Version)", "abs_url": "https://arxiv.org/abs/2510.23895", "pdf_url": "https://arxiv.org/pdf/2510.23895", "authors": ["Hoora Sobhani", "Hyoseung Kim"], "abstract": "Title: Modeling and Scheduling of Fusion Patterns in Autonomous Driving Systems (Extended Version)", "primary_subject": "Systems and Control (eess.SY)", "subjects": ["Systems and Control (eess.SY)", "Operating Systems (cs.OS)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}, {"arxiv_id": "arXiv:2510.23615", "title": "Logic-based Task Representation and Reward Shaping in Multiagent Reinforcement Learning", "abs_url": "https://arxiv.org/abs/2510.23615", "pdf_url": "https://arxiv.org/pdf/2510.23615", "authors": ["Nishant Doshi"], "abstract": "Title: Logic-based Task Representation and Reward Shaping in Multiagent Reinforcement Learning", "primary_subject": "Multiagent Systems (cs.MA)", "subjects": ["Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "section_type": "Authors and titles", "submission_date": "2025-10-29"}], "stats": {"total": 44, "total_authorships": 221, "unique_authors": 211, "section_counts": {"Authors and titles": 44}, "top_authors": [["Junfeng Wu", 3], ["Guangyang Zeng", 2], ["Tengfei Zhang", 2], ["Ziqi Ma", 2], ["Zuxuan Wu", 2]], "top_phrases": [["3d gaussian splatting memory", 2], ["actuated concentric tube robots", 2], ["adaptive inspection planning approach", 2]], "average_authors": 5.0227272727272725}}}, "preferences": {"favorite_authors": ["barron", "Fei-Fei Li"], "keywords": ["reconstruction", "gaussian splatting"]}, "default_source": "cs.CV"}</script>
  <script>


(() => {
  const RAW_DATA = JSON.parse(document.getElementById('digest-data').textContent);
  const SOURCE_STORAGE_KEY = 'arxivDigestSource';
  const PREF_STORAGE_KEY = 'arxivDigestPreferences';
  const DISPLAY_MODE_STORAGE_KEY = 'arxivDigestDisplayMode';
  const DISPLAY_MODE_CLASSES = {
    title: 'display-mode-title',
    authors: 'display-mode-authors',
    full: 'display-mode-full',
  };
  const DISPLAY_MODE_OPTIONS = [
    { key: 'title', label: 'Title only' },
    { key: 'authors', label: 'Title & authors' },
    { key: 'full', label: 'Full details' },
  ];

  const SOURCE_KEYS = Object.keys(RAW_DATA.sources || {});
  if (!SOURCE_KEYS.length) {
    return;
  }
  const generatedAt = RAW_DATA.generated_at || '';
  const initialPreferences = normalizePreferences(RAW_DATA.preferences || {});

  const state = {
    source: loadStoredSource(),
    preferences: loadStoredPreferences(),
    isEditingPreferences: false,
    activeSection: 'stats',
    displayMode: loadStoredDisplayMode(),
    expandedArticles: new Set(),
  };

  if (!RAW_DATA.sources[state.source]) {
    state.source = RAW_DATA.default_source && RAW_DATA.sources[RAW_DATA.default_source]
      ? RAW_DATA.default_source
      : SOURCE_KEYS[0];
  }

  const elements = {
    sourceSwitcher: document.getElementById('source-switcher'),
    displayModeControls: document.getElementById('display-mode-controls'),
    nav: document.querySelector('.sidebar nav'),
    preferencesView: document.getElementById('preferences-view'),
    preferencesForm: document.getElementById('preferences-form'),
    favoriteAuthorsView: document.getElementById('favorite-authors-view'),
    keywordsView: document.getElementById('keywords-view'),
    favoritesInput: document.getElementById('favorite-authors-input'),
    keywordsInput: document.getElementById('keywords-input'),
    editPreferences: document.getElementById('edit-preferences'),
    cancelPreferences: document.getElementById('cancel-preferences'),
    resetPreferences: document.getElementById('reset-preferences'),
    preferencesStatusView: document.getElementById('preferences-status-view'),
    preferencesStatus: document.getElementById('preferences-status'),
    overviewSummary: document.getElementById('overview-summary'),
    overviewBody: document.getElementById('overview-body'),
    statsBody: document.getElementById('stats-body'),
    favoritesBody: document.getElementById('favorite-body'),
    keywordsBody: document.getElementById('keywords-body'),
    categoriesBody: document.getElementById('categories-body'),
    headerSource: document.getElementById('meta-source'),
    headerDate: document.getElementById('meta-date'),
    headerGenerated: document.getElementById('meta-generated'),
    headerTotal: document.getElementById('meta-total'),
    footerSource: document.getElementById('footer-source'),
  };

  document.addEventListener('click', handlePaperClick);
  document.addEventListener('keydown', handlePaperKeydown);

  if (elements.editPreferences) {
    elements.editPreferences.addEventListener('click', () => {
      state.isEditingPreferences = true;
      setStatus('');
      renderPreferencesPanel();
      if (elements.favoritesInput) {
        elements.favoritesInput.focus();
      }
    });
  }

  if (elements.cancelPreferences) {
    elements.cancelPreferences.addEventListener('click', () => {
      state.isEditingPreferences = false;
      setStatus('');
      renderPreferencesPanel();
    });
  }

  if (elements.preferencesForm) {
    elements.preferencesForm.addEventListener('submit', (event) => {
      event.preventDefault();
      const nextPrefs = normalizePreferences({
        favorite_authors: elements.favoritesInput ? elements.favoritesInput.value : '',
        keywords: elements.keywordsInput ? elements.keywordsInput.value : '',
      });
      state.preferences = nextPrefs;
      state.isEditingPreferences = false;
      savePreferences(nextPrefs);
      renderAll({ resetActiveSection: false });
      setStatus('Preferences saved.');
    });
  }

  if (elements.resetPreferences) {
    elements.resetPreferences.addEventListener('click', () => {
      state.preferences = normalizePreferences(initialPreferences);
      state.isEditingPreferences = true;
      savePreferences(state.preferences);
      renderAll({ resetActiveSection: false });
      setStatus('Preferences reset to defaults.');
    });
  }

  renderAll({ resetActiveSection: true });

  function renderAll(options = {}) {
    if (options.resetActiveSection) {
      state.activeSection = 'stats';
    }
    renderSourceButtons();
    renderDisplayModeControls();
    renderPreferencesPanel();

    const sourceData = RAW_DATA.sources[state.source];
    if (!sourceData) {
      return;
    }

    const articles = sourceData.articles || [];
    pruneExpandedArticles(articles);
    applyDisplayModeClass();
    updateHeader(sourceData);
    const overviewCount = renderOverview(sourceData, articles);
    renderStats(sourceData);
    const favoriteCount = renderFavorites(sourceData, articles);
    const keywordCount = renderKeywords(sourceData, articles);
    const categoriesNavItems = renderCategories(sourceData, articles);
    renderNavigation(sourceData, overviewCount, favoriteCount, keywordCount, categoriesNavItems);
    updateFooter(sourceData);
    attachSectionHandlers();
    setActiveSection(state.activeSection);
    updatePaperAria();
  }

  function renderSourceButtons() {
    const container = elements.sourceSwitcher;
    if (!container) return;
    container.innerHTML = SOURCE_KEYS.map((key) => {
      const label = RAW_DATA.sources[key].label || key;
      const active = key === state.source ? 'is-active' : '';
      return `<button type="button" class="source-button ${active}" data-source="${key}">${escapeHtml(label)}</button>`;
    }).join('');
    Array.from(container.querySelectorAll('button[data-source]')).forEach((button) => {
      button.addEventListener('click', () => {
        const nextSource = button.getAttribute('data-source');
        if (!nextSource || nextSource === state.source || !RAW_DATA.sources[nextSource]) return;
        state.source = nextSource;
        saveSource(nextSource);
        setStatus('');
        state.activeSection = 'stats';
        state.expandedArticles.clear();
        renderAll({ resetActiveSection: true });
      });
    });
  }

  function renderDisplayModeControls() {
    const container = elements.displayModeControls;
    if (!container) return;
    const label = `<span class="display-mode__label">Paper view</span>`;
    const buttons = DISPLAY_MODE_OPTIONS.map(({ key, label: buttonLabel }) => {
      return `<button type="button" class="display-mode__button" data-mode="${key}" aria-pressed="false">${escapeHtml(buttonLabel)}</button>`;
    }).join('');
    container.innerHTML = `${label}${buttons}`;
    Array.from(container.querySelectorAll('button[data-mode]')).forEach((button) => {
      button.addEventListener('click', () => {
        const mode = button.getAttribute('data-mode');
        if (!mode) return;
        setDisplayMode(mode);
      });
    });
    updateDisplayModeButtons();
  }

  function setDisplayMode(mode) {
    const normalized = normalizeDisplayMode(mode);
    if (normalized === state.displayMode) {
      return;
    }
    state.displayMode = normalized;
    saveDisplayMode(normalized);
    applyDisplayModeClass();
    updateDisplayModeButtons();
    updatePaperAria();
  }

  function applyDisplayModeClass() {
    const targetClass = DISPLAY_MODE_CLASSES[state.displayMode] || DISPLAY_MODE_CLASSES.full;
    const classList = document.body.classList;
    Object.values(DISPLAY_MODE_CLASSES).forEach((cls) => classList.remove(cls));
    classList.add(targetClass);
  }

  function updateDisplayModeButtons() {
    const container = elements.displayModeControls;
    if (!container) return;
    const activeMode = state.displayMode;
    Array.from(container.querySelectorAll('button[data-mode]')).forEach((button) => {
      const mode = button.getAttribute('data-mode');
      const isActive = mode === activeMode;
      button.classList.toggle('is-active', isActive);
      button.setAttribute('aria-pressed', String(isActive));
    });
  }

  function renderPreferencesPanel() {
    const favorites = state.preferences.favorite_authors || [];
    const keywords = state.preferences.keywords || [];

    if (elements.favoriteAuthorsView) {
      elements.favoriteAuthorsView.innerHTML = favorites.length
        ? favorites.map((item) => `<span class="chip">${escapeHtml(item)}</span>`).join('')
        : '<span class="preferences-empty">None</span>';
    }
    if (elements.keywordsView) {
      elements.keywordsView.innerHTML = keywords.length
        ? keywords.map((item) => `<span class="chip">${escapeHtml(item)}</span>`).join('')
        : '<span class="preferences-empty">None</span>';
    }

    if (state.isEditingPreferences) {
      if (elements.preferencesView) elements.preferencesView.hidden = true;
      if (elements.preferencesForm) elements.preferencesForm.hidden = false;
      updatePreferenceInputs();
    } else {
      if (elements.preferencesView) elements.preferencesView.hidden = false;
      if (elements.preferencesForm) elements.preferencesForm.hidden = true;
    }
  }

  function renderOverview(sourceData, articles) {
    const body = elements.overviewBody;
    if (!body) return 0;
    const summary = elements.overviewSummary;
    const total = articles.length;
    const sourceLabel = sourceData.label || state.source;
    const plural = total === 1 ? '' : 's';
    if (summary) {
      summary.textContent = total + ' paper' + plural + ' from ' + sourceLabel + '.';
    }
    body.innerHTML = articles.map(renderArticleCard).join('') || '<p class="empty-state">No papers available.</p>';
    return total;
  }

  function renderStats(sourceData) {
    const body = elements.statsBody;
    if (!body) return;
    const stats = sourceData.stats || {};
    const total = stats.total || 0;
    const uniqueAuthors = stats.unique_authors || 0;
    const totalAuthorships = stats.total_authorships || 0;
    const averageAuthors = (stats.average_authors || 0).toFixed(2);
    const topAuthors = (stats.top_authors || []).map(([name, count]) => `<li>${escapeHtml(name)} (${count})</li>`).join('') || '<li>None</li>';
    const topPhrases = (stats.top_phrases || []).map(([phrase, count]) => `<li>${escapeHtml(phrase)} (${count})</li>`).join('') || '<li>None</li>';
    const sectionCounts = Object.entries(stats.section_counts || {})
      .sort(([a], [b]) => a.localeCompare(b))
      .map(([section, count]) => `<li>${escapeHtml(section)} (${count})</li>`)
      .join('') || '<li>None</li>';

    body.innerHTML = `
      <div class="stats-grid">
        <div class="stat-card">
          <h3>Papers</h3>
          <p>Total papers: ${total}</p>
          <p>Avg authors per paper: ${averageAuthors}</p>
        </div>
        <div class="stat-card">
          <h3>Authors</h3>
          <p>Unique authors: ${uniqueAuthors}</p>
          <p>Total author mentions: ${totalAuthorships}</p>
        </div>
        <div class="stat-card">
          <h3>Top Authors</h3>
          <ul>${topAuthors}</ul>
        </div>
        <div class="stat-card">
          <h3>Popular Phrases</h3>
          <ul>${topPhrases}</ul>
        </div>
        <div class="stat-card">
          <h3>Section Breakdown</h3>
          <ul>${sectionCounts}</ul>
        </div>
      </div>
    `;
  }

  function renderFavorites(sourceData, articles) {
    const body = elements.favoritesBody;
    if (!body) return 0;
    const favorites = state.preferences.favorite_authors || [];
    const matches = filterByFavoriteAuthors(articles, favorites);
    body.innerHTML = buildWatcherSectionContent(favorites, matches, 'Add authors in the sidebar to highlight researchers you care about.');
    return matches.length;
  }

  function renderKeywords(sourceData, articles) {
    const body = elements.keywordsBody;
    if (!body) return 0;
    const keywords = state.preferences.keywords || [];
    const matches = filterByKeywords(articles, keywords);
    body.innerHTML = buildWatcherSectionContent(keywords, matches, 'Track important topics by adding keywords in the sidebar.');
    return matches.length;
  }

  function buildWatcherSectionContent(items, matches, emptyMessage) {
    const chips = (items || []).map((item) => `<span class="chip">${escapeHtml(item)}</span>`).join('');
    const summary = items.length
      ? `<div class="watcher-summary">Watching <strong>${items.length}</strong> entr${items.length === 1 ? 'y' : 'ies'}.<div class="chip-set">${chips}</div></div>`
      : `<div class="watcher-summary">${emptyMessage}</div>`;
    const articlesHtml = matches.length
      ? matches.map(renderArticleCard).join('')
      : '<p class="empty-state">No papers matched the current filters.</p>';
    return `${summary}${articlesHtml}`;
  }

  function renderCategories(sourceData, articles) {
    const body = elements.categoriesBody;
    if (!body) return [];
    const groups = buildSectionGrouping(articles);
    if (!groups.length) {
      body.innerHTML = '<p class="empty-state">No categories available for this source.</p>';
      return [];
    }
    const sectionsHtml = groups.map(({ sectionId, sectionLabel, count, subjects }) => {
      const subjectHtml = subjects.map(({ subjectId, subjectLabel, items }) => `
        <div class="subject-group" id="${subjectId}">
          <div class="subject-group__header">
            <h4>${escapeHtml(subjectLabel)}</h4>
            <span class="count-chip">${formatCount(items.length)}</span>
          </div>
          ${items.map(renderArticleCard).join('')}
        </div>
      `).join('');
      return `
        <div class="category-block" id="${sectionId}">
          <div class="category-block__header">
            <h3>${escapeHtml(sectionLabel)}</h3>
            <span class="count-chip">${formatCount(count)}</span>
          </div>
          <div class="subject-grid">
            ${subjectHtml}
          </div>
        </div>
      `;
    }).join('');
    body.innerHTML = sectionsHtml;
    return groups.map(({ sectionId, sectionLabel, count, subjects }) => ({
      id: sectionId,
      label: `${sectionLabel} (${count})`,
      children: subjects.map(({ subjectId, subjectLabel, items }) => ({
        id: subjectId,
        label: `${subjectLabel} (${items.length})`,
      })),
    }));
  }

  function renderNavigation(sourceData, overviewCount, favoriteCount, keywordCount, categoriesNavItems) {
    if (!elements.nav) return;
    const navItems = [
      { id: 'stats', label: 'Statistics' },
      { id: 'overview', label: `All Papers (${overviewCount})` },
      { id: 'favorite', label: `Favorite Authors (${favoriteCount})` },
      { id: 'keyword', label: `Watched Keywords (${keywordCount})` },
      { id: 'categories', label: 'Browse by Category', children: categoriesNavItems },
    ];
    elements.nav.innerHTML = buildNavList(navItems);
  }

  function buildNavList(items, level = 1) {
    if (!items || !items.length) return '';
    const listClass = `nav-list nav-level-${level}`;
    const inner = items.map((item) => {
      const children = buildNavList(item.children || [], level + 1);
      return `<li class="nav-item nav-level-${level}"><a href="#${item.id}">${escapeHtml(item.label)}</a>${children}</li>`;
    }).join('');
    return `<ul class="${listClass}">${inner}</ul>`;
  }

  function updateHeader(sourceData) {
    if (elements.headerSource) elements.headerSource.textContent = `Source: ${sourceData.label || state.source}`;
    if (elements.headerDate) elements.headerDate.textContent = `Date: ${sourceData.date || ''}`;
    if (elements.headerGenerated) elements.headerGenerated.textContent = `Generated at: ${generatedAt}`;
    if (elements.headerTotal) elements.headerTotal.textContent = `Total papers: ${(sourceData.stats && sourceData.stats.total) || 0}`;
  }

  function updateFooter(sourceData) {
    if (!elements.footerSource) return;
    elements.footerSource.textContent = sourceData.label || state.source;
    if (sourceData.url) {
      elements.footerSource.setAttribute('href', sourceData.url);
    }
  }

  function attachSectionHandlers() {
    const toggles = Array.from(document.querySelectorAll('.section-toggle'));
    toggles.forEach((toggle) => {
      toggle.onclick = () => {
        const targetId = toggle.getAttribute('data-target');
        if (!targetId) return;
        const section = document.getElementById(targetId);
        if (!section) return;
        const willExpand = section.classList.contains('is-collapsed');
        setSectionState(section, willExpand);
        if (willExpand) {
          state.activeSection = section.id;
          setActiveSection(section.id);
        }
      };
    });
    const navLinks = elements.nav ? Array.from(elements.nav.querySelectorAll('a[href^="#"]')) : [];
    navLinks.forEach((link) => {
      link.onclick = (event) => {
        const href = link.getAttribute('href');
        if (!href || !href.startsWith('#')) return;
        const targetId = href.slice(1);
        const targetElement = document.getElementById(targetId);
        if (!targetElement) return;
        const container = targetElement.classList.contains('content-section')
          ? targetElement
          : targetElement.closest('.content-section');
        if (!container) return;
        event.preventDefault();
        state.activeSection = container.id;
        setActiveSection(container.id, targetElement);
      };
    });
  }

  function setActiveSection(sectionId, focusTarget) {
    state.activeSection = sectionId || 'stats';
    const sections = Array.from(document.querySelectorAll('.content-section'));
    sections.forEach((section) => {
      const isActive = section.id === state.activeSection;
      section.classList.toggle('is-hidden', !isActive);
      if (section.dataset.collapsible === 'true') {
        setSectionState(section, isActive);
      } else {
        section.classList.toggle('is-collapsed', !isActive);
      }
    });
    const activeSection = document.getElementById(state.activeSection);
    if (activeSection) {
      const scrollTarget = focusTarget && activeSection.contains(focusTarget) ? focusTarget : activeSection;
      expandAncestors(scrollTarget);
      scrollTarget.scrollIntoView({ behavior: 'smooth', block: 'start' });
    }
    if (elements.nav) {
      const navLinks = Array.from(elements.nav.querySelectorAll('a[href^="#"]'));
      navLinks.forEach((link) => {
        const href = link.getAttribute('href');
        const id = href ? href.slice(1) : '';
        link.classList.toggle('is-active', id === state.activeSection);
      });
    }
  }

  function updatePaperAria() {
    const cards = Array.from(document.querySelectorAll('.paper'));
    cards.forEach((card) => {
      const paperId = card.getAttribute('data-paper-id') || '';
      const isUserExpanded = paperId && state.expandedArticles.has(paperId);
      const isExpanded = state.displayMode === 'full' || Boolean(isUserExpanded);
      card.setAttribute('aria-expanded', String(isExpanded));
      card.classList.toggle('paper--expanded', Boolean(isUserExpanded));
    });
  }

  function handlePaperClick(event) {
    const paper = event.target.closest('.paper');
    if (!paper) return;
    if (event.target.closest('a')) return;
    togglePaperExpansion(paper);
  }

  function handlePaperKeydown(event) {
    if (event.key !== 'Enter' && event.key !== ' ') return;
    const paper = event.target.closest('.paper');
    if (!paper) return;
    if (event.key === ' ') {
      event.preventDefault();
    }
    togglePaperExpansion(paper);
  }

  function togglePaperExpansion(paper) {
    const paperId = paper.getAttribute('data-paper-id') || '';
    if (!paperId) return;
    if (state.expandedArticles.has(paperId)) {
      state.expandedArticles.delete(paperId);
    } else {
      state.expandedArticles.add(paperId);
    }
    updatePaperAria();
  }

  function setSectionState(section, expanded) {
    if (expanded) {
      section.classList.add('is-expanded');
      section.classList.remove('is-collapsed');
    } else {
      section.classList.add('is-collapsed');
      section.classList.remove('is-expanded');
    }
    const toggle = section.querySelector('.section-toggle');
    if (toggle) {
      toggle.setAttribute('aria-expanded', String(expanded));
      toggle.textContent = expanded ? 'Hide section' : 'Show section';
    }
  }

  function expandAncestors(element) {
    if (!element) return;
    let parent = element.closest('[data-collapsible="true"]');
    while (parent) {
      setSectionState(parent, true);
      parent = parent.parentElement ? parent.parentElement.closest('[data-collapsible="true"]') : null;
    }
  }

  function renderArticleCard(article) {
    const articleId = String(article.arxiv_id || article.id || '');
    const authors = escapeHtml((article.authors || []).join(', '));
    const subjects = escapeHtml((article.subjects || []).join('; '));
    const abstract = escapeHtml(article.abstract);
    const pdfLink = article.pdf_url ? `<a href="${article.pdf_url}" target="_blank" rel="noopener">PDF</a>` : '';
    const isUserExpanded = state.expandedArticles.has(articleId);
    const ariaExpanded = state.displayMode === 'full' || isUserExpanded;
    const expandedClass = isUserExpanded ? ' paper--expanded' : '';
    return `
      <article class="paper${expandedClass}" data-paper-id="${escapeHtml(articleId)}" tabindex="0" aria-expanded="${ariaExpanded}">
        <h3><a href="${article.abs_url}" target="_blank" rel="noopener">${escapeHtml(article.title)}</a></h3>
        <p class="meta">
          <span class="id">${escapeHtml(article.arxiv_id)}</span>
          <span class="authors">${authors}</span>
        </p>
        <p class="subjects">${subjects}</p>
        <p class="abstract">${abstract}</p>
        <p class="links"><a href="${article.abs_url}" target="_blank" rel="noopener">Abstract</a> ${pdfLink}</p>
      </article>
    `;
  }

  function buildSectionGrouping(articles) {
    const sections = new Map();
    articles.forEach((article) => {
      const sectionKey = article.section_type || 'Other';
      const subjectKey = article.primary_subject || 'Other';
      if (!sections.has(sectionKey)) {
        sections.set(sectionKey, new Map());
      }
      const subjectMap = sections.get(sectionKey);
      if (!subjectMap.has(subjectKey)) {
        subjectMap.set(subjectKey, []);
      }
      subjectMap.get(subjectKey).push(article);
    });

    return Array.from(sections.entries())
      .sort(([a], [b]) => a.localeCompare(b))
      .map(([sectionName, subjectMap]) => {
        const sectionId = `category-${slugify(sectionName)}`;
        const subjects = Array.from(subjectMap.entries())
          .sort(([a], [b]) => a.localeCompare(b))
          .map(([subjectName, items]) => ({
            subjectId: `${sectionId}-${slugify(subjectName, 'subject')}`,
            subjectLabel: subjectName,
            items,
          }));
        const count = subjects.reduce((sum, entry) => sum + entry.items.length, 0);
        return {
          sectionId,
          sectionLabel: sectionName,
          count,
          subjects,
        };
      });
  }

  function filterByFavoriteAuthors(articles, favoriteAuthors) {
    const favorites = (favoriteAuthors || []).map((name) => name.toLowerCase()).filter(Boolean);
    if (!favorites.length) return [];
    return articles.filter((article) => {
      const authorLower = article.authors.map((name) => name.toLowerCase());
      return favorites.some((fav) => authorLower.some((author) => author.includes(fav)));
    });
  }

  function filterByKeywords(articles, keywords) {
    const needles = (keywords || []).map((kw) => kw.toLowerCase()).filter(Boolean);
    if (!needles.length) return [];
    return articles.filter((article) => {
      const haystack = `${article.title} ${article.abstract}`.toLowerCase();
      return needles.some((needle) => haystack.includes(needle));
    });
  }

  function pruneExpandedArticles(articles) {
    const ids = new Set(
      (articles || []).map((article) => String(article.arxiv_id || article.id || '')).filter((value) => value),
    );
    Array.from(state.expandedArticles).forEach((storedId) => {
      if (!ids.has(storedId)) {
        state.expandedArticles.delete(storedId);
      }
    });
  }

  function updatePreferenceInputs() {
    if (elements.favoritesInput) {
      elements.favoritesInput.value = state.preferences.favorite_authors.join('\n');
    }
    if (elements.keywordsInput) {
      elements.keywordsInput.value = state.preferences.keywords.join('\n');
    }
  }

  function setStatus(message) {
    if (elements.preferencesStatus) {
      elements.preferencesStatus.textContent = state.isEditingPreferences ? message : '';
    }
    if (elements.preferencesStatusView) {
      elements.preferencesStatusView.textContent = state.isEditingPreferences ? '' : message;
    }
  }

  function escapeHtml(value) {
    return String(value || '')
      .replace(/&/g, '&amp;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&gt;')
      .replace(/"/g, '&quot;')
      .replace(/'/g, '&#39;');
  }

  function slugify(text, fallback = 'section') {
    const slug = String(text || '')
      .trim()
      .toLowerCase()
      .replace(/[^a-z0-9]+/g, '-')
      .replace(/^-+|-+$/g, '');
    return slug || fallback;
  }

  function formatCount(value) {
    const count = Number(value) || 0;
    return `${count} paper${count === 1 ? '' : 's'}`;
  }

  function normalizeDisplayMode(value) {
    if (typeof value !== 'string') {
      return 'full';
    }
    const normalized = value.trim().toLowerCase();
    return Object.prototype.hasOwnProperty.call(DISPLAY_MODE_CLASSES, normalized) ? normalized : 'full';
  }

  function normalizePreferences(raw) {
    const normalizeList = (value) => {
      if (Array.isArray(value)) {
        const cleaned = value.map((item) => String(item).trim()).filter((item) => item);
        return Array.from(new Set(cleaned));
      }
      if (typeof value === 'string') {
        const cleaned = value
          .split(/[\n,]/)
          .map((item) => item.trim())
          .filter((item) => item);
        return Array.from(new Set(cleaned));
      }
      return [];
    };
    return {
      favorite_authors: normalizeList(raw.favorite_authors),
      keywords: normalizeList(raw.keywords),
    };
  }

  function loadStoredDisplayMode() {
    try {
      const stored = localStorage.getItem(DISPLAY_MODE_STORAGE_KEY);
      return normalizeDisplayMode(stored);
    } catch (_) {
      return 'full';
    }
  }

  function saveDisplayMode(mode) {
    try {
      localStorage.setItem(DISPLAY_MODE_STORAGE_KEY, normalizeDisplayMode(mode));
    } catch (_) {}
  }

  function loadStoredSource() {
    try {
      return localStorage.getItem(SOURCE_STORAGE_KEY) || '';
    } catch (_) {
      return '';
    }
  }

  function saveSource(value) {
    try {
      localStorage.setItem(SOURCE_STORAGE_KEY, value);
    } catch (_) {}
  }

  function loadStoredPreferences() {
    try {
      const raw = localStorage.getItem(PREF_STORAGE_KEY);
      return raw ? normalizePreferences(JSON.parse(raw)) : normalizePreferences(initialPreferences);
    } catch (_) {
      return normalizePreferences(initialPreferences);
    }
  }

  function savePreferences(prefs) {
    try {
      localStorage.setItem(PREF_STORAGE_KEY, JSON.stringify(prefs));
    } catch (_) {}
  }
})();

  

  </script>
</body>
</html>
